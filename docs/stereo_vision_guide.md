# ìŠ¤í…Œë ˆì˜¤ë¹„ì „(Stereo Vision) í•™ìŠµ ê°€ì´ë“œ

## ğŸš€ ìŠ¤í…Œë ˆì˜¤ë¹„ì „ì˜ ê°œìš”

ìŠ¤í…Œë ˆì˜¤ë¹„ì „ì€ ë‘ ê°œì˜ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•˜ì—¬ 3ì°¨ì› ê¹Šì´ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì»´í“¨í„° ë¹„ì „ ê¸°ìˆ ì…ë‹ˆë‹¤. LiDAR ëŒ€ë¹„ ì €ë¹„ìš©ìœ¼ë¡œ ê±°ë¦¬ ì¸¡ì •ì´ ê°€ëŠ¥í•˜ì—¬ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë©ë‹ˆë‹¤.

### ğŸ¯ ì£¼ìš” ì‘ìš© ë¶„ì•¼
- **ììœ¨ì£¼í–‰**: ì „ë°© ì°¨ëŸ‰ ê±°ë¦¬ ì¸¡ì • ë° ì¥ì• ë¬¼ ê°ì§€
- **ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜**: ì‹¤ë‚´ ì¥ì• ë¬¼ íšŒí”¼ ì‹œìŠ¤í…œ
- **AR/VR**: ì‹¤ì‹œê°„ 3D í™˜ê²½ ì¬êµ¬ì„±
- **ì œì¡°ì—…**: ë¶€í’ˆ í’ˆì§ˆ ê²€ì‚¬ ìë™í™”

## ğŸ“š ëª©ì°¨
1. [StereoVisionì´ë€?](#1-stereovisionì´ë€)
2. [Stereo Visionì˜ 3ì°¨ì› ê±°ë¦¬ ì •ë³´ ê³„ì‚°](#2-stereo-visionì˜-3ì°¨ì›-ê±°ë¦¬-ì •ë³´-ê³„ì‚°)
3. [Stereo Matchingì„ í†µí•œ Disparity Map íšë“](#3-stereo-matchingì„-í†µí•œ-disparity-map-íšë“)
4. [StereoVision ì½”ë“œ êµ¬í˜„](#4-stereovision-ì½”ë“œ-êµ¬í˜„)
5. [ğŸ”§ ì‹¤ë¬´ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ](#5-ì‹¤ë¬´-íŠ¸ëŸ¬ë¸”ìŠˆíŒ…-ê°€ì´ë“œ)
6. [âš¡ ì„±ëŠ¥ ìµœì í™” ë…¸í•˜ìš°](#6-ì„±ëŠ¥-ìµœì í™”-ë…¸í•˜ìš°)
7. [ğŸ“Š ì‹¤ì œ í”„ë¡œì íŠ¸ ì¼€ì´ìŠ¤ ìŠ¤í„°ë””](#7-ì‹¤ì œ-í”„ë¡œì íŠ¸-ì¼€ì´ìŠ¤-ìŠ¤í„°ë””)

---

## 1. StereoVisionì´ë€?

### ğŸ” ê¸°ë³¸ ê°œë…

![ìŠ¤í…Œë ˆì˜¤ë¹„ì „ ê°œë…](../images/image1.png)

**ìŠ¤í…Œë ˆì˜¤ë¹„ì „ì´ë€?**
- ì‚¬ëŒì˜ ì–‘ì•ˆì‹œ ì›ë¦¬ë¥¼ ëª¨ë°©í•˜ì—¬ 2ì°¨ì› ì˜ìƒìœ¼ë¡œë¶€í„° 3ì°¨ì› ê¹Šì´ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ê¸°ìˆ 
- ë‘ ê°œì˜ ì¹´ë©”ë¼ë¡œ ì´¬ì˜í•œ ì¢Œ/ìš° ì˜ìƒì˜ **ì‹œì°¨(disparity)**ë¥¼ ì´ìš©í•˜ì—¬ ê±°ë¦¬ ì •ë³´ë¥¼ ê³„ì‚°
- ì¸ê°„ì˜ ë‡Œê°€ ì¢Œ/ìš° ëˆˆì˜ ì˜ìƒì„ ìœµí•©í•˜ì—¬ ê¹Šì´ê°ì„ ì¸ì§€í•˜ëŠ” ê²ƒê³¼ ë™ì¼í•œ ì›ë¦¬

**ê¸°ìˆ ì  ë„ì „ ìš”ì†Œ:**
- ì •ë°€í•œ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
- ìŠ¤í…Œë ˆì˜¤ ì˜ìƒ ì •ë ¬
- íš¨ìœ¨ì ì¸ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”

### ğŸ“Š ë¬¼ì²´ ì •ë³´ íšë“ ë°©ë²• ë¹„êµ

```mermaid
flowchart TB
D["ë¬¼ì²´ì˜ ì •ë³´ íšë“ ë°©ë²•"]
D --> A["3ì°¨ì› ì •ë³´"]
D --> A_1["2ì°¨ì› ì •ë³´"]
A --> B_1["ë¹„ì ‘ì´‰ì‹ ë°©ë²•"] & B_2["ì ‘ì´‰ì‹ ë°©ë²•"]
B_1 --> C_1["ë ˆì´ì € ì‚¼ê°ë²•"] & C_2["ê³µì´ˆì  í˜„ë¯¸ê²½"] & C_3["í”„ë¦°ì§€ íˆ¬ì˜ë²•"] & C_4(("Stereo Vision"))
```

### âœ… ìŠ¤í…Œë ˆì˜¤ë¹„ì „ì˜ ì¥ë‹¨ì 

**ì¥ì :**
- ì €ë¹„ìš© (ì¼ë°˜ ì¹´ë©”ë¼ 2ëŒ€ë§Œ í•„ìš”)
- ì¸¡ì • ë²”ìœ„ê°€ ë„“ìŒ
- ì‹œìŠ¤í…œ êµ¬ì„±ì´ ê°„ë‹¨
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥

**ë‹¨ì :**
- ì •í™•ë„ê°€ ë‹¤ë¥¸ 3D ì¸¡ì • ë°©ë²•ì— ë¹„í•´ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŒ
- ì¡°ëª… ì¡°ê±´ì— ë¯¼ê°
- í…ìŠ¤ì²˜ê°€ ì—†ëŠ” í‘œë©´ì—ì„œ ì„±ëŠ¥ ì €í•˜

**ì£¼ì˜ì‚¬í•­:** í•˜ì–€ ë²½ë©´ì´ë‚˜ ë‹¨ìƒ‰ í‘œë©´ì—ì„œëŠ” ë§¤ì¹­ì´ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ê²½ìš° í”„ë¡œì í„°ë¡œ íŒ¨í„´ì„ íˆ¬ì‚¬í•˜ëŠ” 'Structured Light' ë°©ì‹ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 2. Stereo Visionì˜ 3ì°¨ì› ê±°ë¦¬ ì •ë³´ ê³„ì‚°

### ğŸ“ ê¸°ë³¸ ì›ë¦¬

![3ì°¨ì› ê±°ë¦¬ ê³„ì‚°](../images/image3.png)

**í•µì‹¬ ë§¤ê°œë³€ìˆ˜:**
- **b**: Baseline (ë‘ ì¹´ë©”ë¼ ì¤‘ì‹¬ê°„ ê±°ë¦¬)
- **f**: Focal Length (ì´ˆì ê±°ë¦¬)  
- **d**: Disparity (ì‹œì°¨) = x_L - x_R
- **z**: Distance (ì‹¤ì œ 3ì°¨ì› ê±°ë¦¬)

### ğŸ§® ìˆ˜í•™ì  ìœ ë„ ê³¼ì •

**1ë‹¨ê³„: ë¹„ë¡€ì‹ ì„¤ì •**
```
x_L : f = (x + b/2) : z
x_R : f = (x - b/2) : z
```

**2ë‹¨ê³„: ì‹ ë³€í˜•**
```
x_L Ã— z = f Ã— (x + b/2)
x_R Ã— z = f Ã— (x - b/2)
```

**3ë‹¨ê³„: ë‘ ì‹ì˜ ì°¨ì´ ê³„ì‚°**
```
(x_L - x_R) Ã— z = f Ã— b
d Ã— z = f Ã— b
```

**4ë‹¨ê³„: ìµœì¢… ê±°ë¦¬ ê³µì‹**
```
z = (f Ã— b) / d
```

### ğŸ’¡ í•µì‹¬ ê¹¨ë‹¬ìŒ
1. **ì‹œì°¨ê°€ í´ìˆ˜ë¡** â†’ ê±°ë¦¬ê°€ ê°€ê¹Œì›€
2. **ì‹œì°¨ê°€ ì‘ì„ìˆ˜ë¡** â†’ ê±°ë¦¬ê°€ ë©€ìŒ
3. **ë² ì´ìŠ¤ë¼ì¸ì´ í´ìˆ˜ë¡** â†’ ì¸¡ì • ì •í™•ë„ í–¥ìƒ
4. **ì´ˆì ê±°ë¦¬ê°€ í´ìˆ˜ë¡** â†’ ì¸¡ì • ì •í™•ë„ í–¥ìƒ

**ë² ì´ìŠ¤ë¼ì¸ ì„¤ê³„ ì›ì¹™:** ë² ì´ìŠ¤ë¼ì¸ì„ ë„ˆë¬´ í¬ê²Œ í•˜ë©´ ê²¹ì¹˜ëŠ” ì˜ì—­(Overlap)ì´ ì¤„ì–´ë“¤ì–´ ë§¤ì¹­í•  ìˆ˜ ìˆëŠ” ì˜ì—­ì´ ì‘ì•„ì§‘ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì¸¡ì • ê±°ë¦¬ì˜ 1/10 ì •ë„ê°€ ìµœì ìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.

### ğŸ”§ ì‹¤ì œ ê³„ì‚° ì˜ˆì‹œ

```python
def calculate_depth(focal_length, baseline, disparity):
    """
    ê¹Šì´ ê³„ì‚° í•¨ìˆ˜
    
    Args:
        focal_length: ì´ˆì ê±°ë¦¬ (pixels)
        baseline: ë² ì´ìŠ¤ë¼ì¸ (meters)  
        disparity: ì‹œì°¨ (pixels)
    
    Returns:
        depth: ê¹Šì´ (meters)
    """
    if disparity > 0:
        depth = (focal_length * baseline) / disparity
        return depth
    else:
        return float('inf')  # ë¬´í•œëŒ€ (ë§¤ì¹­ ì‹¤íŒ¨)

# ì˜ˆì‹œ ê³„ì‚°
f = 700  # 700 pixels
b = 0.12  # 12 cm
d = 50   # 50 pixels

distance = calculate_depth(f, b, d)
print(f"ê³„ì‚°ëœ ê±°ë¦¬: {distance:.2f} meters")
```

### ğŸ“Š ê±°ë¦¬ë³„ ì •í™•ë„ ë¶„ì„

```python
import matplotlib.pyplot as plt
import numpy as np

def accuracy_analysis():
    """ê±°ë¦¬ë³„ ì •í™•ë„ ë¶„ì„"""
    distances = np.linspace(0.5, 10, 100)
    focal_length = 700
    baseline = 0.12
    
    # ì‹œì°¨ ê³„ì‚°
    disparities = (focal_length * baseline) / distances
    
    # 1í”½ì…€ ì˜¤ì°¨ ì‹œ ê±°ë¦¬ ì˜¤ì°¨
    error_distances = (focal_length * baseline) / (disparities - 1)
    relative_errors = np.abs(error_distances - distances) / distances * 100
    
    plt.figure(figsize=(12, 5))
    
    plt.subplot(121)
    plt.plot(distances, disparities)
    plt.xlabel('ì‹¤ì œ ê±°ë¦¬ (m)')
    plt.ylabel('ì‹œì°¨ (pixels)')
    plt.title('ê±°ë¦¬ vs ì‹œì°¨')
    plt.grid(True)
    
    plt.subplot(122)
    plt.plot(distances, relative_errors)
    plt.xlabel('ì‹¤ì œ ê±°ë¦¬ (m)')
    plt.ylabel('ìƒëŒ€ ì˜¤ì°¨ (%)')
    plt.title('ê±°ë¦¬ë³„ ìƒëŒ€ ì˜¤ì°¨ (1í”½ì…€ ì˜¤ì°¨ ê°€ì •)')
    plt.grid(True)
    
    plt.tight_layout()
    plt.show()

# accuracy_analysis()
```

---

## 3. Stereo Matchingì„ í†µí•œ Disparity Map íšë“

### ğŸ¯ ìŠ¤í…Œë ˆì˜¤ ì •í•©ì´ë€?

![ìŠ¤í…Œë ˆì˜¤ ì •í•©](../images/image5.png)

**ì •ì˜:** ì¢Œì¸¡ ì˜ìƒì˜ í•œ ì ì— ëŒ€ì‘í•˜ëŠ” ì ì„ ìš°ì¸¡ ì˜ìƒì—ì„œ ì°¾ëŠ” ê³¼ì •

**ê²°ê³¼ë¬¼:** 
- **Disparity Map**: ê° í”½ì…€ì˜ ì‹œì°¨ ê°’ì„ ì˜ìƒìœ¼ë¡œ í‘œí˜„
- ê°€ê¹Œìš´ ë¬¼ì²´ â†’ ë°ê²Œ (í° ì‹œì°¨)
- ë¨¼ ë¬¼ì²´ â†’ ì–´ë‘¡ê²Œ (ì‘ì€ ì‹œì°¨)

**ì„±ëŠ¥ ê³ ë ¤ì‚¬í•­:** ì™„ë²½í•œ ë§¤ì¹­ì€ í˜„ì‹¤ì ìœ¼ë¡œ ì–´ë ¤ìš°ë©°, í•­ìƒ Trade-offë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ì£¼ìš” ê³ ë ¤ì‚¬í•­ì€ ì†ë„ vs ì •í™•ë„, ë©”ëª¨ë¦¬ vs í’ˆì§ˆ ë“±ì…ë‹ˆë‹¤.

### ğŸ“‹ ìŠ¤í…Œë ˆì˜¤ ì •í•© ë°©ë²• ë¶„ë¥˜

#### ğŸŒ ì „ì—­ ì •í•© (Global Matching)
- ì˜ìƒ ì „ì²´ì˜ ì •ë³´ë¥¼ ë™ì‹œì— ê³ ë ¤
- ë†’ì€ ì •í™•ë„, ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜
- **ì¢…ë¥˜**: Semi-Global Matching (SGM), Graph-Cut, Belief Propagation

#### ğŸ  ì§€ì—­ ì •í•© (Local Matching)  
- ìœˆë„ìš° ë‹¨ìœ„ë¡œ êµ­ì†Œì  ì •í•©
- ë¹ ë¥¸ ì²˜ë¦¬, ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì •í™•ë„
- **ì¢…ë¥˜**: SAD, SSD, Census Transform

**ì„±ëŠ¥ ë¹„êµ (640x480 ê¸°ì¤€)**:
- **SAD**: ~30ms
- **SGBM**: ~150ms  
- **Graph-Cut**: ~800ms
*ì¼ë°˜ì ì¸ Intel i7, single thread í™˜ê²½*

### ğŸ” ì§€ì—­ ì •í•© ë°©ë²• ìƒì„¸

#### SAD (Sum of Absolute Difference)
![SAD](../images/image8.png)

```python
def compute_SAD(left_window, right_window):
    """SAD ë¹„ìš© ê³„ì‚°"""
    return np.sum(np.abs(left_window - right_window))
```

**ìˆ˜ì‹:** `SAD = Î£|I_L(x,y) - I_R(x,y)|`

#### SSD (Sum of Squared Difference)
![SSD](../images/image9.png)

```python
def compute_SSD(left_window, right_window):
    """SSD ë¹„ìš© ê³„ì‚°"""
    return np.sum((left_window - right_window) ** 2)
```

**ìˆ˜ì‹:** `SSD = Î£(I_L(x,y) - I_R(x,y))Â²`

#### Census Transform
![Census Transform](../images/image10.png)

**íŠ¹ì§•:** ì¡°ëª… ë³€í™”ì— ê°•í•¨

**ê³¼ì •:**
1. ì¤‘ì‹¬ í”½ì…€ê³¼ ì£¼ë³€ í”½ì…€ ë¹„êµ
2. ì‘ìœ¼ë©´ '1', í¬ë©´ '0'ìœ¼ë¡œ íŒ¨í„´ ìƒì„±
3. ë¹„íŠ¸ íŒ¨í„´ì„ ë²¡í„°ë¡œ ë³€í™˜
4. XOR ì—°ì‚°ìœ¼ë¡œ ì°¨ì´ ê³„ì‚°

```python
def census_transform(image, window_size=5):
    """Census Transform ì ìš©"""
    h, w = image.shape
    census = np.zeros((h, w), dtype=np.uint64)
    
    offset = window_size // 2
    
    for y in range(offset, h - offset):
        for x in range(offset, w - offset):
            center = image[y, x]
            bit_string = 0
            
            for dy in range(-offset, offset + 1):
                for dx in range(-offset, offset + 1):
                    if dy == 0 and dx == 0:
                        continue
                    bit_string <<= 1
                    if image[y + dy, x + dx] < center:
                        bit_string |= 1
            
            census[y, x] = bit_string
    
    return census
```

**Census Transform íŠ¹ì§•:** ì¡°ëª… ë³€í™”ì— ê°•í•´ ì•¼ì™¸ í™˜ê²½ì—ì„œ ìœ ìš©í•©ë‹ˆë‹¤. ë‹¤ë§Œ ê³„ì‚°ëŸ‰ì´ ë§ì•„ ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° GPU ê°€ì†ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

### âš™ï¸ Winner-Takes-All ì „ëµ

```python
def winner_takes_all(cost_volume):
    """
    ìµœì†Œ ë¹„ìš©ì„ ê°€ì§€ëŠ” ì‹œì°¨ ì„ íƒ
    
    Args:
        cost_volume: (H, W, D) ë¹„ìš© ë³¼ë¥¨
    
    Returns:
        disparity_map: (H, W) ì‹œì°¨ ë§µ
    """
    disparity_map = np.argmin(cost_volume, axis=2)
    return disparity_map
```

### ğŸ”§ í›„ì²˜ë¦¬ ê¸°ë²•

**ì£¼ìš” í›„ì²˜ë¦¬ ë°©ë²•:**
1. **Left-Right Consistency Check**: ì¢Œìš° ì¼ê´€ì„± ê²€ì‚¬
2. **Median Filter**: ì¡ìŒ ì œê±°
3. **Weighted Median Filter**: ê°€ì¤‘ ì¤‘ê°„ê°’ í•„í„°
4. **Hole Filling**: ë¹ˆ ì˜ì—­ ì±„ìš°ê¸°

```python
def left_right_consistency_check(disp_left, disp_right, threshold=1):
    """ì¢Œìš° ì¼ê´€ì„± ê²€ì‚¬"""
    h, w = disp_left.shape
    consistent_mask = np.zeros((h, w), dtype=bool)
    
    for y in range(h):
        for x in range(w):
            d = disp_left[y, x]
            if 0 <= x - d < w:
                if abs(disp_left[y, x] - disp_right[y, x - d]) <= threshold:
                    consistent_mask[y, x] = True
    
    return consistent_mask
```

---

## 4. StereoVision ì½”ë“œ êµ¬í˜„

### ğŸ Python êµ¬í˜„ (OpenCV ì‚¬ìš©)

#### ê¸°ë³¸ êµ¬í˜„

```python
import cv2
import numpy as np
import matplotlib.pyplot as plt

def basic_stereo_matching():
    """ê¸°ë³¸ ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­"""
    # ì˜ìƒ ë¡œë“œ
    imgL = cv2.imread('left_image.png', 0)
    imgR = cv2.imread('right_image.png', 0)
    
    # StereoBM ê°ì²´ ìƒì„±
    stereo = cv2.StereoBM_create(numDisparities=64, blockSize=15)
    
    # ì‹œì°¨ ë§µ ê³„ì‚°
    disparity = stereo.compute(imgL, imgR)
    
    # ì‹œê°í™”
    plt.figure(figsize=(15, 5))
    
    plt.subplot(131)
    plt.imshow(imgL, cmap='gray')
    plt.title('Left Image')
    
    plt.subplot(132)
    plt.imshow(imgR, cmap='gray')
    plt.title('Right Image')
    
    plt.subplot(133)
    plt.imshow(disparity, cmap='jet')
    plt.title('Disparity Map')
    plt.colorbar()
    
    plt.show()
    
    return disparity
```

#### ê³ ê¸‰ êµ¬í˜„ (StereoSGBM)

```python
def advanced_stereo_matching():
    """ê³ ê¸‰ ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­ (SGBM)"""
    # ì˜ìƒ ë¡œë“œ
    imgL = cv2.imread('left_image.png', 0)
    imgR = cv2.imread('right_image.png', 0)
    
    # StereoSGBM ë§¤ê°œë³€ìˆ˜ ì„¤ì •
    window_size = 5
    min_disp = 0
    num_disp = 64
    
    stereo = cv2.StereoSGBM_create(
        minDisparity=min_disp,
        numDisparities=num_disp,
        blockSize=window_size,
        P1=8 * 3 * window_size ** 2,
        P2=32 * 3 * window_size ** 2,
        disp12MaxDiff=1,
        uniquenessRatio=10,
        speckleWindowSize=100,
        speckleRange=32
    )
    
    # ì‹œì°¨ ë§µ ê³„ì‚°
    disparity = stereo.compute(imgL, imgR).astype(np.float32) / 16.0
    
    return disparity
```

#### ì™„ì „í•œ ìŠ¤í…Œë ˆì˜¤ë¹„ì „ ì‹œìŠ¤í…œ

```python
class StereoVisionSystem:
    def __init__(self, focal_length, baseline):
        self.focal_length = focal_length
        self.baseline = baseline
        self.stereo = cv2.StereoSGBM_create(
            minDisparity=0,
            numDisparities=64,
            blockSize=5,
            uniquenessRatio=10,
            speckleWindowSize=100,
            speckleRange=32
        )
    
    def compute_disparity(self, img_left, img_right):
        """ì‹œì°¨ ë§µ ê³„ì‚°"""
        disparity = self.stereo.compute(img_left, img_right)
        disparity = disparity.astype(np.float32) / 16.0
        return disparity
    
    def disparity_to_depth(self, disparity):
        """ì‹œì°¨ë¥¼ ê¹Šì´ë¡œ ë³€í™˜"""
        # 0ì¸ ì‹œì°¨ ê°’ì„ ë¬´í•œëŒ€ë¡œ ì²˜ë¦¬
        depth = np.zeros_like(disparity)
        valid_pixels = disparity > 0
        depth[valid_pixels] = (self.focal_length * self.baseline) / disparity[valid_pixels]
        return depth
    
    def create_point_cloud(self, disparity, img_left):
        """3D ì êµ° ìƒì„±"""
        h, w = disparity.shape
        
        # ì¢Œí‘œ ê²©ì ìƒì„±
        x, y = np.meshgrid(np.arange(w), np.arange(h))
        
        # ê¹Šì´ ê³„ì‚°
        depth = self.disparity_to_depth(disparity)
        
        # 3D ì¢Œí‘œ ê³„ì‚°
        X = (x - w/2) * depth / self.focal_length
        Y = (y - h/2) * depth / self.focal_length
        Z = depth
        
        # ìœ íš¨í•œ ì ë“¤ë§Œ ì„ íƒ
        valid = (depth > 0) & (depth < 10)  # 10m ì´ë‚´
        
        points = np.column_stack([
            X[valid], Y[valid], Z[valid]
        ])
        
        colors = img_left[valid] if len(img_left.shape) == 2 else img_left[valid]
        
        return points, colors
    
    def process_stereo_pair(self, img_left, img_right):
        """ìŠ¤í…Œë ˆì˜¤ ìŒ ì²˜ë¦¬"""
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(img_left.shape) == 3:
            gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)
            gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)
        else:
            gray_left = img_left
            gray_right = img_right
        
        # ì‹œì°¨ ê³„ì‚°
        disparity = self.compute_disparity(gray_left, gray_right)
        
        # ê¹Šì´ ê³„ì‚°
        depth = self.disparity_to_depth(disparity)
        
        # ì êµ° ìƒì„±
        points, colors = self.create_point_cloud(disparity, gray_left)
        
        return {
            'disparity': disparity,
            'depth': depth,
            'points_3d': points,
            'colors': colors
        }

# ì‚¬ìš© ì˜ˆì‹œ
def main():
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    focal_length = 700  # í”½ì…€
    baseline = 0.12     # ë¯¸í„°
    
    stereo_system = StereoVisionSystem(focal_length, baseline)
    
    # ì˜ìƒ ë¡œë“œ
    img_left = cv2.imread('left.png')
    img_right = cv2.imread('right.png')
    
    # ì²˜ë¦¬
    results = stereo_system.process_stereo_pair(img_left, img_right)
    
    # ê²°ê³¼ ì‹œê°í™”
    plt.figure(figsize=(15, 10))
    
    plt.subplot(231)
    plt.imshow(cv2.cvtColor(img_left, cv2.COLOR_BGR2RGB))
    plt.title('Left Image')
    
    plt.subplot(232)
    plt.imshow(cv2.cvtColor(img_right, cv2.COLOR_BGR2RGB))
    plt.title('Right Image')
    
    plt.subplot(233)
    plt.imshow(results['disparity'], cmap='jet')
    plt.title('Disparity Map')
    plt.colorbar()
    
    plt.subplot(234)
    plt.imshow(results['depth'], cmap='jet', vmax=5)
    plt.title('Depth Map (m)')
    plt.colorbar()
    
    plt.tight_layout()
    plt.show()
    
    return results

if __name__ == "__main__":
    results = main()
```

### ğŸš€ ì‹¤ì‹œê°„ ìŠ¤í…Œë ˆì˜¤ë¹„ì „

```python
def real_time_stereo():
    """ì‹¤ì‹œê°„ ìŠ¤í…Œë ˆì˜¤ë¹„ì „"""
    # ì›¹ìº  ì´ˆê¸°í™” (ë“€ì–¼ ì¹´ë©”ë¼ í•„ìš”)
    cap_left = cv2.VideoCapture(0)
    cap_right = cv2.VideoCapture(1)
    
    # ìŠ¤í…Œë ˆì˜¤ ë§¤ì²˜ ì´ˆê¸°í™”
    stereo = cv2.StereoBM_create(numDisparities=32, blockSize=15)
    
    while True:
        ret_left, frame_left = cap_left.read()
        ret_right, frame_right = cap_right.read()
        
        if ret_left and ret_right:
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2GRAY)
            gray_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2GRAY)
            
            # ì‹œì°¨ ê³„ì‚°
            disparity = stereo.compute(gray_left, gray_right)
            
            # ì •ê·œí™”
            disp_norm = cv2.normalize(disparity, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
            
            # ê²°ê³¼ í‘œì‹œ
            combined = np.hstack((frame_left, frame_right))
            cv2.imshow('Stereo Cameras', combined)
            cv2.imshow('Disparity', disp_norm)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    
    cap_left.release()
    cap_right.release()
    cv2.destroyAllWindows()
```

---

## 5. ğŸ”§ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### ë¬¸ì œ 1: ì‹œì°¨ ë§µì´ ë…¸ì´ì¦ˆë¡œ ê°€ë“í•´ìš”!

**ì¦ìƒ:**
- ì ë“¤ì´ ë„ì—„ë„ì—„ ë‚˜íƒ€ë‚¨
- ì—°ì†ì ì´ì§€ ì•Šì€ ì‹œì°¨ ê°’
- ê°™ì€ ë¬¼ì²´ì„ì—ë„ ì‹œì°¨ê°€ ë¶ˆê·œì¹™

**ì›ì¸ê³¼ í•´ê²°ì±…:**

```python
def diagnose_noisy_disparity():
    """ë…¸ì´ì¦ˆ ì§„ë‹¨ ë° í•´ê²°"""
    
    # 1. ì˜ìƒ í’ˆì§ˆ ê²€ì‚¬
    def check_image_quality(img_left, img_right):
        # ëŒ€ë¹„ ê²€ì‚¬
        contrast_left = img_left.std()
        contrast_right = img_right.std()
        
        if contrast_left < 20 or contrast_right < 20:
            print("âš ï¸  ëŒ€ë¹„ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì¡°ëª…ì„ ê°œì„ í•˜ì„¸ìš”.")
        
        # í…ìŠ¤ì²˜ ê²€ì‚¬
        laplacian_left = cv2.Laplacian(img_left, cv2.CV_64F).var()
        if laplacian_left < 100:
            print("âš ï¸  í…ìŠ¤ì²˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. íŒ¨í„´ íˆ¬ì‚¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
        
        return contrast_left, contrast_right, laplacian_left
    
    # 2. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ìƒíƒœ ê²€ì‚¬
    def check_calibration(img_left, img_right):
        # SIFT íŠ¹ì§•ì  ë§¤ì¹­ìœ¼ë¡œ ì •ë ¬ ìƒíƒœ í™•ì¸
        sift = cv2.SIFT_create()
        kp1, des1 = sift.detectAndCompute(img_left, None)
        kp2, des2 = sift.detectAndCompute(img_right, None)
        
        bf = cv2.BFMatcher()
        matches = bf.knnMatch(des1, des2, k=2)
        
        good_matches = []
        for m, n in matches:
            if m.distance < 0.75 * n.distance:
                good_matches.append(m)
        
        if len(good_matches) < 50:
            print("âš ï¸  ì¹´ë©”ë¼ ì •ë ¬ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ì¬ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”.")
            
        return len(good_matches)
    
    # 3. ë§¤ê°œë³€ìˆ˜ ìë™ íŠœë‹
    def auto_tune_parameters(img_left, img_right):
        best_score = 0
        best_params = None
        
        block_sizes = [5, 7, 9, 11, 15]
        num_disparities = [32, 48, 64, 80, 96]
        
        for block_size in block_sizes:
            for num_disp in num_disparities:
                stereo = cv2.StereoBM_create(
                    numDisparities=num_disp, 
                    blockSize=block_size
                )
                
                disparity = stereo.compute(img_left, img_right)
                
                # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ìœ íš¨ í”½ì…€ ë¹„ìœ¨)
                valid_pixels = (disparity > 0).sum()
                total_pixels = disparity.size
                score = valid_pixels / total_pixels
                
                if score > best_score:
                    best_score = score
                    best_params = (block_size, num_disp)
        
        print(f"ìµœì  ë§¤ê°œë³€ìˆ˜: blockSize={best_params[0]}, numDisparities={best_params[1]}")
        return best_params
```

#### ë¬¸ì œ 2: íŠ¹ì • ì˜ì—­ì—ì„œ ë§¤ì¹­ì´ ì•ˆ ë¼ìš”!

**í•´ê²° ì „ëµ:**

```python
def handle_matching_failures():
    """ë§¤ì¹­ ì‹¤íŒ¨ ì˜ì—­ ì²˜ë¦¬"""
    
    def detect_problematic_regions(img):
        """ë¬¸ì œ ì˜ì—­ íƒì§€"""
        # 1. ì €ëŒ€ë¹„ ì˜ì—­
        local_std = cv2.blur(cv2.pow(img.astype(np.float32), 2), (15, 15)) - \
                   cv2.pow(cv2.blur(img.astype(np.float32), (15, 15)), 2)
        low_contrast_mask = local_std < 100
        
        # 2. ë°˜ë³µ íŒ¨í„´ ì˜ì—­
        edges = cv2.Canny(img, 50, 150)
        edge_density = cv2.blur(edges.astype(np.float32), (15, 15))
        repetitive_mask = edge_density > 100
        
        # 3. ê³¼í¬í™” ì˜ì—­
        overexposed_mask = img > 240
        underexposed_mask = img < 15
        
        problematic_mask = low_contrast_mask | repetitive_mask | \
                          overexposed_mask | underexposed_mask
        
        return problematic_mask
    
    def adaptive_preprocessing(img_left, img_right):
        """ì ì‘ì  ì „ì²˜ë¦¬"""
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        img_left_enhanced = clahe.apply(img_left)
        img_right_enhanced = clahe.apply(img_right)
        
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        img_left_smooth = cv2.GaussianBlur(img_left_enhanced, (3, 3), 0)
        img_right_smooth = cv2.GaussianBlur(img_right_enhanced, (3, 3), 0)
        
        return img_left_smooth, img_right_smooth
```

**ë§¤ì¹­ ì‹¤íŒ¨ ëŒ€ì‘:** ë§¤ì¹­ ì‹¤íŒ¨ëŠ” ì™„ì „íˆ í”¼í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì‹¤íŒ¨ë¥¼ ë¹¨ë¦¬ ê°ì§€í•˜ê³  ëŒ€ì•ˆì„ ë§ˆë ¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. IMU ì„¼ì„œì™€ ìœµí•©í•˜ì—¬ ì¼ì‹œì  ë§¤ì¹­ ì‹¤íŒ¨ë¥¼ ë³´ìƒí•˜ëŠ” ë°©ë²•ì´ íš¨ê³¼ì ì…ë‹ˆë‹¤.

#### ë¬¸ì œ 3: ì‹¤ì‹œê°„ ì²˜ë¦¬ ì†ë„ê°€ ë„ˆë¬´ ëŠë ¤ìš”!

**ì„±ëŠ¥ ìµœì í™” ì „ëµ:**

```python
def optimize_for_realtime():
    """ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”"""
    
    # 1. í•´ìƒë„ ë‹¤ìš´ìƒ˜í”Œë§
    def multi_scale_processing(img_left, img_right, scale_factor=0.5):
        # ì €í•´ìƒë„ì—ì„œ ë¹ ë¥¸ ë§¤ì¹­
        small_left = cv2.resize(img_left, None, fx=scale_factor, fy=scale_factor)
        small_right = cv2.resize(img_right, None, fx=scale_factor, fy=scale_factor)
        
        # ë¹ ë¥¸ ë§¤ì¹­
        stereo_fast = cv2.StereoBM_create(numDisparities=32, blockSize=9)
        disparity_small = stereo_fast.compute(small_left, small_right)
        
        # ì—…ìƒ˜í”Œë§
        disparity_upscaled = cv2.resize(disparity_small, 
                                       (img_left.shape[1], img_left.shape[0]))
        disparity_upscaled = disparity_upscaled / scale_factor
        
        return disparity_upscaled
    
    # 2. ROI ê¸°ë°˜ ì²˜ë¦¬
    def roi_based_stereo(img_left, img_right, roi_rect):
        """ê´€ì‹¬ ì˜ì—­ë§Œ ì²˜ë¦¬"""
        x, y, w, h = roi_rect
        
        roi_left = img_left[y:y+h, x:x+w]
        roi_right = img_right[y:y+h, x:x+w]
        
        stereo = cv2.StereoBM_create(numDisparities=64, blockSize=15)
        roi_disparity = stereo.compute(roi_left, roi_right)
        
        # ì „ì²´ ì˜ìƒ í¬ê¸°ë¡œ í™•ì¥
        full_disparity = np.zeros_like(img_left, dtype=np.int16)
        full_disparity[y:y+h, x:x+w] = roi_disparity
        
        return full_disparity
    
    # 3. í”„ë ˆì„ ìŠ¤í‚¤í•‘
    class FrameSkippingStereo:
        def __init__(self, skip_frames=2):
            self.skip_frames = skip_frames
            self.frame_count = 0
            self.last_disparity = None
            
        def process(self, img_left, img_right):
            self.frame_count += 1
            
            if self.frame_count % (self.skip_frames + 1) == 0:
                # ì‹¤ì œ ì²˜ë¦¬
                stereo = cv2.StereoBM_create(numDisparities=64, blockSize=15)
                self.last_disparity = stereo.compute(img_left, img_right)
            
            return self.last_disparity
```

---

## 6. âš¡ ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

### ğŸš€ GPU ê°€ì† í™œìš©

```python
def gpu_accelerated_stereo():
    """GPU ê°€ì† ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­"""
    
    # CUDA ì‚¬ìš© ê°€ëŠ¥ í™•ì¸
    if not cv2.cuda.getCudaEnabledDeviceCount():
        print("CUDAë¥¼ ì§€ì›í•˜ëŠ” GPUê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # GPU ë©”ëª¨ë¦¬ì— ì˜ìƒ ì—…ë¡œë“œ
    def process_with_gpu(img_left, img_right):
        # CPUì—ì„œ GPUë¡œ ì—…ë¡œë“œ
        gpu_left = cv2.cuda_GpuMat()
        gpu_right = cv2.cuda_GpuMat()
        gpu_left.upload(img_left)
        gpu_right.upload(img_right)
        
        # GPUì—ì„œ ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­
        stereo_gpu = cv2.cuda.createStereoBM(numDisparities=64, blockSize=19)
        gpu_disparity = cv2.cuda_GpuMat()
        stereo_gpu.compute(gpu_left, gpu_right, gpu_disparity)
        
        # GPUì—ì„œ CPUë¡œ ë‹¤ìš´ë¡œë“œ
        disparity = gpu_disparity.download()
        
        return disparity
    
    return process_with_gpu

# ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
def benchmark_stereo_methods():
    """ë‹¤ì–‘í•œ ë°©ë²•ì˜ ì„±ëŠ¥ ë¹„êµ"""
    import time
    
    methods = {
        'StereoBM': cv2.StereoBM_create(numDisparities=64, blockSize=15),
        'StereoSGBM': cv2.StereoSGBM_create(
            minDisparity=0, numDisparities=64, blockSize=5,
            P1=600, P2=2400, disp12MaxDiff=10,
            uniquenessRatio=5, speckleWindowSize=50, speckleRange=1
        )
    }
    
    # í…ŒìŠ¤íŠ¸ ì˜ìƒ (640x480 ê°€ì •)
    img_left = np.random.randint(0, 255, (480, 640), dtype=np.uint8)
    img_right = np.random.randint(0, 255, (480, 640), dtype=np.uint8)
    
    results = {}
    
    for name, stereo in methods.items():
        times = []
        for _ in range(10):  # 10íšŒ ë°˜ë³µ ì¸¡ì •
            start_time = time.time()
            disparity = stereo.compute(img_left, img_right)
            end_time = time.time()
            times.append(end_time - start_time)
        
        avg_time = np.mean(times)
        fps = 1.0 / avg_time
        results[name] = {'time': avg_time, 'fps': fps}
        
        print(f"{name}: {avg_time:.3f}s ({fps:.1f} FPS)")
    
    return results
```

### ğŸ¯ ë©”ëª¨ë¦¬ ìµœì í™”

```python
class EfficientStereoMatcher:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ìŠ¤í…Œë ˆì˜¤ ë§¤ì²˜"""
    
    def __init__(self, max_disparity=64, block_size=15):
        self.max_disparity = max_disparity
        self.block_size = block_size
        self.stereo = cv2.StereoBM_create(
            numDisparities=max_disparity, 
            blockSize=block_size
        )
        
        # ë©”ëª¨ë¦¬ í’€ ë¯¸ë¦¬ í• ë‹¹
        self.disparity_buffer = None
        self.temp_left = None
        self.temp_right = None
    
    def process_inplace(self, img_left, img_right):
        """ë©”ëª¨ë¦¬ ì¬ì‚¬ìš©ìœ¼ë¡œ ì²˜ë¦¬"""
        h, w = img_left.shape
        
        # ë²„í¼ ì´ˆê¸°í™” (ì²« ì‹¤í–‰ì‹œë§Œ)
        if self.disparity_buffer is None:
            self.disparity_buffer = np.zeros((h, w), dtype=np.int16)
            self.temp_left = np.zeros((h, w), dtype=np.uint8)
            self.temp_right = np.zeros((h, w), dtype=np.uint8)
        
        # ê¸°ì¡´ ë°°ì—´ ì¬ì‚¬ìš©
        np.copyto(self.temp_left, img_left)
        np.copyto(self.temp_right, img_right)
        
        # ì „ì²˜ë¦¬ (ì¸í”Œë ˆì´ìŠ¤)
        cv2.GaussianBlur(self.temp_left, (3, 3), 0, self.temp_left)
        cv2.GaussianBlur(self.temp_right, (3, 3), 0, self.temp_right)
        
        # ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­
        self.disparity_buffer = self.stereo.compute(self.temp_left, self.temp_right)
        
        return self.disparity_buffer

# ë©€í‹°ìŠ¤ë ˆë”© ìµœì í™”
from concurrent.futures import ThreadPoolExecutor
import threading

class MultiThreadStereo:
    """ë©€í‹°ìŠ¤ë ˆë“œ ìŠ¤í…Œë ˆì˜¤ ì²˜ë¦¬"""
    
    def __init__(self, num_threads=4):
        self.num_threads = num_threads
        self.executor = ThreadPoolExecutor(max_workers=num_threads)
        self.lock = threading.Lock()
    
    def process_regions(self, img_left, img_right, regions):
        """ì˜ì—­ë³„ ë³‘ë ¬ ì²˜ë¦¬"""
        
        def process_region(region_info):
            region_id, (x, y, w, h) = region_info
            
            # ì˜ì—­ ì¶”ì¶œ
            region_left = img_left[y:y+h, x:x+w]
            region_right = img_right[y:y+h, x:x+w]
            
            # ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­
            stereo = cv2.StereoBM_create(numDisparities=32, blockSize=9)
            region_disparity = stereo.compute(region_left, region_right)
            
            return region_id, (x, y), region_disparity
        
        # ë³‘ë ¬ ì²˜ë¦¬
        futures = []
        for i, region in enumerate(regions):
            future = self.executor.submit(process_region, (i, region))
            futures.append(future)
        
        # ê²°ê³¼ ìˆ˜ì§‘
        full_disparity = np.zeros(img_left.shape, dtype=np.int16)
        
        for future in futures:
            region_id, (x, y), region_disparity = future.result()
            h, w = region_disparity.shape
            full_disparity[y:y+h, x:x+w] = region_disparity
        
        return full_disparity
```

### ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
class StereoPerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, window_size=30):
        self.window_size = window_size
        self.frame_times = []
        self.quality_scores = []
        
    def update(self, process_time, disparity_map):
        """ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸"""
        self.frame_times.append(process_time)
        if len(self.frame_times) > self.window_size:
            self.frame_times.pop(0)
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        valid_pixels = (disparity_map > 0).sum()
        total_pixels = disparity_map.size
        quality = valid_pixels / total_pixels
        
        self.quality_scores.append(quality)
        if len(self.quality_scores) > self.window_size:
            self.quality_scores.pop(0)
    
    def get_stats(self):
        """í†µê³„ ì •ë³´ ë°˜í™˜"""
        if not self.frame_times:
            return None
        
        avg_time = np.mean(self.frame_times)
        avg_fps = 1.0 / avg_time
        avg_quality = np.mean(self.quality_scores)
        
        return {
            'avg_fps': avg_fps,
            'avg_time': avg_time,
            'avg_quality': avg_quality,
            'min_fps': 1.0 / max(self.frame_times),
            'max_fps': 1.0 / min(self.frame_times)
        }
    
    def should_adjust_quality(self, target_fps=25):
        """í’ˆì§ˆ ì¡°ì • í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        stats = self.get_stats()
        if stats and stats['avg_fps'] < target_fps:
            return True
        return False

# ì ì‘ì  í’ˆì§ˆ ì¡°ì •
class AdaptiveQualityStereo:
    """ì ì‘ì  í’ˆì§ˆ ì¡°ì • ìŠ¤í…Œë ˆì˜¤"""
    
    def __init__(self, target_fps=25):
        self.target_fps = target_fps
        self.monitor = StereoPerformanceMonitor()
        
        # í’ˆì§ˆ ë ˆë²¨ë³„ ì„¤ì •
        self.quality_levels = [
            {'numDisparities': 32, 'blockSize': 9, 'scale': 0.5},   # ë‚®ìŒ
            {'numDisparities': 48, 'blockSize': 11, 'scale': 0.75}, # ë³´í†µ
            {'numDisparities': 64, 'blockSize': 15, 'scale': 1.0},  # ë†’ìŒ
        ]
        
        self.current_level = 1  # ë³´í†µìœ¼ë¡œ ì‹œì‘
    
    def process_adaptive(self, img_left, img_right):
        """ì ì‘ì  ì²˜ë¦¬"""
        import time
        
        start_time = time.time()
        
        # í˜„ì¬ í’ˆì§ˆ ë ˆë²¨ ì„¤ì •
        config = self.quality_levels[self.current_level]
        
        # ìŠ¤ì¼€ì¼ ì¡°ì •
        scale = config['scale']
        if scale < 1.0:
            h, w = img_left.shape
            new_h, new_w = int(h * scale), int(w * scale)
            img_left = cv2.resize(img_left, (new_w, new_h))
            img_right = cv2.resize(img_right, (new_w, new_h))
        
        # ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­
        stereo = cv2.StereoBM_create(
            numDisparities=config['numDisparities'],
            blockSize=config['blockSize']
        )
        disparity = stereo.compute(img_left, img_right)
        
        # ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
        if scale < 1.0:
            original_shape = (img_left.shape[1] // scale, img_left.shape[0] // scale)
            disparity = cv2.resize(disparity, original_shape)
            disparity = disparity / scale
        
        process_time = time.time() - start_time
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.monitor.update(process_time, disparity)
        
        # í’ˆì§ˆ ë ˆë²¨ ì¡°ì •
        self._adjust_quality_level()
        
        return disparity
    
    def _adjust_quality_level(self):
        """í’ˆì§ˆ ë ˆë²¨ ìë™ ì¡°ì •"""
        stats = self.monitor.get_stats()
        if not stats:
            return
        
        current_fps = stats['avg_fps']
        
        if current_fps < self.target_fps * 0.8:  # ë„ˆë¬´ ëŠë¦¼
            if self.current_level > 0:
                self.current_level -= 1
                print(f"í’ˆì§ˆ ë ˆë²¨ í•˜í–¥: {self.current_level}")
        
        elif current_fps > self.target_fps * 1.2:  # ì—¬ìœ  ìˆìŒ
            if self.current_level < len(self.quality_levels) - 1:
                self.current_level += 1
                print(f"í’ˆì§ˆ ë ˆë²¨ ìƒí–¥: {self.current_level}")
```

---

## 7. ğŸ“Š ì‘ìš© ë¶„ì•¼ë³„ êµ¬í˜„ ì‚¬ë¡€

### ğŸš— ì¼€ì´ìŠ¤ 1: ììœ¨ì£¼í–‰ ì°¨ëŸ‰ì˜ ì „ë°© ê±°ë¦¬ ì¸¡ì •

**í”„ë¡œì íŠ¸ ê°œìš”:**
- **ëª©í‘œ**: ì „ë°© ì°¨ëŸ‰ê³¼ì˜ ê±°ë¦¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸¡ì •
- **ìš”êµ¬ì‚¬í•­**: 30fps, Â±10cm ì •í™•ë„, 5-50m ë²”ìœ„
- **í™˜ê²½**: ì•¼ì™¸, ë‹¤ì–‘í•œ ì¡°ëª… ì¡°ê±´

**ê¸°ìˆ ì  ë„ì „ê³¼ í•´ê²°ì±…:**

```python
class AutonomousCarStereo:
    """ììœ¨ì£¼í–‰ìš© ìŠ¤í…Œë ˆì˜¤ë¹„ì „ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        # ì°¨ëŸ‰ìš© ì¹´ë©”ë¼ ì„¤ì • (ë„“ì€ ë² ì´ìŠ¤ë¼ì¸)
        self.focal_length = 1200  # ê³ í•´ìƒë„ ì¹´ë©”ë¼
        self.baseline = 0.5       # 50cm ë² ì´ìŠ¤ë¼ì¸
        
        # ë„ë¡œ íŠ¹í™” ROI ì„¤ì •
        self.roi_y_start = 0.4    # í™”ë©´ í•˜ë‹¨ 60%ë§Œ ì²˜ë¦¬
        
        # ë‹¤ì¤‘ ì•Œê³ ë¦¬ì¦˜ ìœµí•©
        self.stereo_bm = cv2.StereoBM_create(numDisparities=128, blockSize=15)
        self.stereo_sgbm = cv2.StereoSGBM_create(
            minDisparity=0, numDisparities=128, blockSize=5,
            P1=600, P2=2400, disp12MaxDiff=10,
            uniquenessRatio=5, speckleWindowSize=50, speckleRange=2
        )
        
        # ì‹œê°„ì  í•„í„°ë§
        self.depth_history = []
        self.history_size = 5
    
    def detect_vehicles(self, img_left):
        """ì°¨ëŸ‰ ê²€ì¶œ (YOLO ë“± í™œìš©)"""
        # ì‹¤ì œë¡œëŠ” YOLO, SSD ë“± ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ HOG ê¸°ë°˜ ê²€ì¶œ ì‹œë®¬ë ˆì´ì…˜
        
        # ì°¨ëŸ‰ í›„ë³´ ì˜ì—­ë“¤
        vehicle_rois = [
            (200, 100, 240, 160),  # (x, y, w, h)
            (400, 120, 200, 140),
        ]
        
        return vehicle_rois
    
    def calculate_vehicle_distance(self, img_left, img_right):
        """ì°¨ëŸ‰ë³„ ê±°ë¦¬ ê³„ì‚°"""
        # 1. ì°¨ëŸ‰ ê²€ì¶œ
        vehicle_rois = self.detect_vehicles(img_left)
        
        # 2. ê° ì°¨ëŸ‰ë³„ ì‹œì°¨ ê³„ì‚°
        vehicle_distances = []
        
        for roi in vehicle_rois:
            x, y, w, h = roi
            
            # ROI ì˜ì—­ ì¶”ì¶œ
            roi_left = img_left[y:y+h, x:x+w]
            roi_right = img_right[y:y+h, x:x+w]
            
            # ê³ í’ˆì§ˆ ë§¤ì¹­ (SGBM)
            disparity_roi = self.stereo_sgbm.compute(roi_left, roi_right)
            
            # ì¤‘ì•™ ì˜ì—­ì˜ ì¤‘ê°„ê°’ ê±°ë¦¬ ì‚¬ìš© (robust)
            center_region = disparity_roi[h//3:2*h//3, w//3:2*w//3]
            valid_disparities = center_region[center_region > 0]
            
            if len(valid_disparities) > 0:
                median_disparity = np.median(valid_disparities) / 16.0
                distance = (self.focal_length * self.baseline) / median_disparity
                
                # ì‹œê°„ì  í•„í„°ë§
                distance = self._temporal_filter(distance)
                
                vehicle_distances.append({
                    'roi': roi,
                    'distance': distance,
                    'confidence': len(valid_disparities) / center_region.size
                })
        
        return vehicle_distances
    
    def _temporal_filter(self, new_distance):
        """ì‹œê°„ì  ì¼ê´€ì„±ì„ ìœ„í•œ í•„í„°ë§"""
        self.depth_history.append(new_distance)
        if len(self.depth_history) > self.history_size:
            self.depth_history.pop(0)
        
        # ì´ìƒì¹˜ ì œê±° í›„ í‰ê· 
        depths = np.array(self.depth_history)
        q25, q75 = np.percentile(depths, [25, 75])
        iqr = q75 - q25
        lower_bound = q25 - 1.5 * iqr
        upper_bound = q75 + 1.5 * iqr
        
        filtered_depths = depths[(depths >= lower_bound) & (depths <= upper_bound)]
        
        return np.mean(filtered_depths) if len(filtered_depths) > 0 else new_distance

# ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„
def analyze_autonomous_car_performance():
    """ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¶„ì„"""
    
    # ì¼ë°˜ì ì¸ ì„±ëŠ¥ ì§€í‘œ
    performance_metrics = {
        'detection_success_rate': 0.95,  # 95% ì„±ê³µë¥ 
        'accuracy_within_10cm': 0.89,   # 10cm ì´ë‚´ ì •í™•ë„
        'accuracy_within_20cm': 0.96,   # 20cm ì´ë‚´ ì •í™•ë„
        'false_positive_rate': 0.02,    # 2% ì˜¤íƒë¥ 
        'average_processing_time': 0.028,  # 28ms (35.7 FPS)
    }
    
    print("ğŸ“Š ììœ¨ì£¼í–‰ ìŠ¤í…Œë ˆì˜¤ë¹„ì „ ì„±ëŠ¥ ì§€í‘œ:")
    print(f"âœ… ì„±ê³µë¥ : {performance_metrics['detection_success_rate']*100:.1f}%")
    print(f"ğŸ¯ 10cm ì´ë‚´ ì •í™•ë„: {performance_metrics['accuracy_within_10cm']*100:.1f}%")
    print(f"âš¡ í‰ê·  ì²˜ë¦¬ ì†ë„: {1/performance_metrics['average_processing_time']:.1f} FPS")
    
    return performance_metrics
```

### ğŸ¤– ì¼€ì´ìŠ¤ 2: ì‹¤ë‚´ ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜

**í”„ë¡œì íŠ¸ ê°œìš”:**
- **ëª©í‘œ**: ì‹¤ë‚´ ì²­ì†Œ ë¡œë´‡ì˜ ì¥ì• ë¬¼ íšŒí”¼
- **ìš”êµ¬ì‚¬í•­**: 15fps, 0.1-3m ë²”ìœ„, ì €ë¹„ìš©
- **í™˜ê²½**: ì‹¤ë‚´, ì¼ì •í•œ ì¡°ëª…, ë‹¤ì–‘í•œ í…ìŠ¤ì²˜

```python
class IndoorRobotStereo:
    """ì‹¤ë‚´ ë¡œë´‡ìš© ìŠ¤í…Œë ˆì˜¤ë¹„ì „"""
    
    def __init__(self):
        # ë¡œë´‡ìš© ì„¤ì • (ì§§ì€ ë² ì´ìŠ¤ë¼ì¸, ë„“ì€ í™”ê°)
        self.focal_length = 400
        self.baseline = 0.08  # 8cm (ì†Œí˜• ë¡œë´‡)
        
        # ì‹¤ë‚´ í™˜ê²½ ìµœì í™”
        self.stereo = cv2.StereoBM_create(
            numDisparities=64,
            blockSize=21,      # í° ë¸”ë¡ìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ
        )
        
        # ì¥ì• ë¬¼ ë§µ ìƒì„±
        self.obstacle_map = None
        self.map_resolution = 0.05  # 5cm per pixel
    
    def create_obstacle_map(self, img_left, img_right):
        """ì¥ì• ë¬¼ ë§µ ìƒì„±"""
        # ì‹œì°¨ ê³„ì‚°
        disparity = self.stereo.compute(img_left, img_right)
        
        # ê¹Šì´ë¡œ ë³€í™˜
        depth = np.zeros_like(disparity, dtype=np.float32)
        valid_pixels = disparity > 0
        depth[valid_pixels] = (self.focal_length * self.baseline) / \
                             (disparity[valid_pixels].astype(np.float32) / 16.0)
        
        # ë°”ë‹¥ê³¼ ì¥ì• ë¬¼ ë¶„ë¦¬
        obstacle_mask = self._separate_floor_obstacles(depth)
        
        # íƒ‘ë·° ë§µìœ¼ë¡œ ë³€í™˜
        top_view_map = self._convert_to_top_view(depth, obstacle_mask)
        
        return top_view_map
    
    def _separate_floor_obstacles(self, depth):
        """ë°”ë‹¥ê³¼ ì¥ì• ë¬¼ ë¶„ë¦¬"""
        h, w = depth.shape
        
        # ë°”ë‹¥ ì˜ì—­ ì¶”ì • (í™”ë©´ í•˜ë‹¨)
        floor_region = depth[int(h*0.7):, :]
        floor_depth = np.median(floor_region[floor_region > 0])
        
        # ë°”ë‹¥ë³´ë‹¤ ê°€ê¹Œìš´ ê²ƒë“¤ì„ ì¥ì• ë¬¼ë¡œ íŒë‹¨
        obstacle_mask = (depth > 0) & (depth < floor_depth * 0.9)
        
        # ë…¸ì´ì¦ˆ ì œê±°
        kernel = np.ones((5, 5), np.uint8)
        obstacle_mask = cv2.morphologyEx(
            obstacle_mask.astype(np.uint8), 
            cv2.MORPH_CLOSE, kernel
        )
        
        return obstacle_mask.astype(bool)
    
    def _convert_to_top_view(self, depth, obstacle_mask):
        """íƒ‘ë·° ë§µìœ¼ë¡œ ë³€í™˜"""
        h, w = depth.shape
        
        # ì‹¤ì œ ì¢Œí‘œ ê³„ì‚°
        y_coords, x_coords = np.mgrid[0:h, 0:w]
        
        # ì¹´ë©”ë¼ ì¢Œí‘œê³„ì—ì„œ ì‹¤ì œ ì¢Œí‘œë¡œ ë³€í™˜
        real_x = (x_coords - w/2) * depth / self.focal_length
        real_z = depth
        
        # íƒ‘ë·° ë§µ í¬ê¸° (3m x 3m, 5cm í•´ìƒë„)
        map_size = int(3.0 / self.map_resolution)
        top_view = np.zeros((map_size, map_size), dtype=np.uint8)
        
        # ì¥ì• ë¬¼ í¬ì¸íŠ¸ë¥¼ íƒ‘ë·°ì— ë§¤í•‘
        for y in range(h):
            for x in range(w):
                if obstacle_mask[y, x] and depth[y, x] > 0:
                    # ì‹¤ì œ ì¢Œí‘œ
                    real_x_val = real_x[y, x]
                    real_z_val = real_z[y, x]
                    
                    # íƒ‘ë·° í”½ì…€ ì¢Œí‘œ
                    map_x = int((real_x_val + 1.5) / self.map_resolution)
                    map_y = int(real_z_val / self.map_resolution)
                    
                    if 0 <= map_x < map_size and 0 <= map_y < map_size:
                        top_view[map_y, map_x] = 255
        
        return top_view
    
    def plan_path(self, obstacle_map, target_x, target_y):
        """ê²½ë¡œ ê³„íš (ê°„ë‹¨í•œ A* ì•Œê³ ë¦¬ì¦˜)"""
        # ì‹¤ì œë¡œëŠ” ROS navigation stack ë“± ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜
        
        # ì•ˆì „ ê±°ë¦¬ í™•ì¥
        kernel = np.ones((5, 5), np.uint8)
        expanded_obstacles = cv2.dilate(obstacle_map, kernel, iterations=2)
        
        # ììœ  ê³µê°„ì—ì„œ ëª©í‘œì ìœ¼ë¡œì˜ ì§ì„  ê²½ë¡œ ì²´í¬
        start_x, start_y = obstacle_map.shape[1]//2, 0  # ë¡œë´‡ ìœ„ì¹˜
        
        # ë¸Œë ˆì  í–„ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì§ì„  ê²½ë¡œ ì²´í¬
        path_clear = self._check_line_clear(
            expanded_obstacles, start_x, start_y, target_x, target_y
        )
        
        if path_clear:
            return [(start_x, start_y), (target_x, target_y)]
        else:
            # ì¥ì• ë¬¼ íšŒí”¼ ê²½ë¡œ ê³„ì‚° (ê°„ë‹¨í™”)
            return self._find_detour_path(expanded_obstacles, start_x, start_y, target_x, target_y)
    
    def _check_line_clear(self, obstacle_map, x0, y0, x1, y1):
        """ì§ì„  ê²½ë¡œê°€ ììœ ë¡œìš´ì§€ í™•ì¸"""
        # ë¸Œë ˆì  í–„ ì§ì„  ì•Œê³ ë¦¬ì¦˜
        points = []
        dx = abs(x1 - x0)
        dy = abs(y1 - y0)
        sx = 1 if x0 < x1 else -1
        sy = 1 if y0 < y1 else -1
        err = dx - dy
        
        x, y = x0, y0
        
        while True:
            if 0 <= x < obstacle_map.shape[1] and 0 <= y < obstacle_map.shape[0]:
                if obstacle_map[y, x] > 0:  # ì¥ì• ë¬¼ ë°œê²¬
                    return False
            
            if x == x1 and y == y1:
                break
                
            e2 = 2 * err
            if e2 > -dy:
                err -= dy
                x += sx
            if e2 < dx:
                err += dx
                y += sy
        
        return True
```

### ğŸ­ ì¼€ì´ìŠ¤ 3: ì œì¡°ì—… í’ˆì§ˆ ê²€ì‚¬

**í”„ë¡œì íŠ¸ ê°œìš”:**
- **ëª©í‘œ**: PCB ë¶€í’ˆì˜ ë†’ì´ ì¸¡ì •ìœ¼ë¡œ ë‚©ë•œ ë¶ˆëŸ‰ ê²€ì¶œ
- **ìš”êµ¬ì‚¬í•­**: Î¼m ë‹¨ìœ„ ì •ë°€ë„, ê³ ì •ëœ í™˜ê²½
- **íŠ¹ì§•**: ìµœê³  í’ˆì§ˆ ìš°ì„ , ì†ë„ëŠ” ì°¨ìˆœìœ„

```python
class ManufacturingQualityInspection:
    """ì œì¡°ì—… í’ˆì§ˆ ê²€ì‚¬ìš© ìŠ¤í…Œë ˆì˜¤ë¹„ì „"""
    
    def __init__(self):
        # ê³ ì •ë°€ ì„¤ì •
        self.focal_length = 2000  # ê³ í•´ìƒë„ ì‚°ì—…ìš© ì¹´ë©”ë¼
        self.baseline = 0.3       # 30cm (ì •ë°€ë„ í–¥ìƒ)
        
        # ìµœê³  í’ˆì§ˆ ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­
        self.stereo = cv2.StereoSGBM_create(
            minDisparity=0,
            numDisparities=256,    # ë†’ì€ í•´ìƒë„
            blockSize=3,           # ì‘ì€ ë¸”ë¡ìœ¼ë¡œ ì •ë°€ë„ í–¥ìƒ
            P1=24,
            P2=96,
            disp12MaxDiff=1,       # ì—„ê²©í•œ ì¼ê´€ì„± ì²´í¬
            uniquenessRatio=15,    # ë†’ì€ ìœ ë‹ˆí¬ë‹ˆìŠ¤
            speckleWindowSize=10,
            speckleRange=1
        )
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì •ë³´ (ì‹¤ì œë¡œëŠ” ì •ë°€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”)
        self.camera_matrix = np.array([
            [2000, 0, 320],
            [0, 2000, 240],
            [0, 0, 1]
        ], dtype=np.float32)
        
        self.distortion = np.zeros(5, dtype=np.float32)
    
    def measure_component_heights(self, img_left, img_right, pcb_template):
        """PCB ë¶€í’ˆ ë†’ì´ ì¸¡ì •"""
        
        # 1. PCB ì •ë ¬ (í…œí”Œë¦¿ ë§¤ì¹­)
        aligned_left, aligned_right = self._align_pcb(
            img_left, img_right, pcb_template
        )
        
        # 2. ê³ í’ˆì§ˆ ì‹œì°¨ ê³„ì‚°
        disparity = self._compute_high_quality_disparity(
            aligned_left, aligned_right
        )
        
        # 3. ë¶€í’ˆ ì˜ì—­ ê²€ì¶œ
        component_regions = self._detect_components(aligned_left)
        
        # 4. ê° ë¶€í’ˆë³„ ë†’ì´ ì¸¡ì •
        height_measurements = []
        
        for component in component_regions:
            height_data = self._measure_component_height(
                disparity, component['region'], component['type']
            )
            height_measurements.append(height_data)
        
        return height_measurements
    
    def _align_pcb(self, img_left, img_right, template):
        """PCB ì •ë ¬"""
        # í…œí”Œë¦¿ ë§¤ì¹­ìœ¼ë¡œ PCB ìœ„ì¹˜ ì°¾ê¸°
        result = cv2.matchTemplate(img_left, template, cv2.TM_CCOEFF_NORMED)
        _, _, _, max_loc = cv2.minMaxLoc(result)
        
        # íšŒì „ ë³´ì • (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì •ë ¬ í•„ìš”)
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ í‰í–‰ì´ë™ë§Œ ê³ ë ¤
        x_offset, y_offset = max_loc
        
        # ì •ë ¬ëœ ì˜ìƒ ì¶”ì¶œ
        h, w = template.shape
        aligned_left = img_left[y_offset:y_offset+h, x_offset:x_offset+w]
        aligned_right = img_right[y_offset:y_offset+h, x_offset:x_offset+w]
        
        return aligned_left, aligned_right
    
    def _compute_high_quality_disparity(self, img_left, img_right):
        """ê³ í’ˆì§ˆ ì‹œì°¨ ê³„ì‚°"""
        
        # 1. ì „ì²˜ë¦¬
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        smooth_left = cv2.GaussianBlur(img_left, (3, 3), 0.5)
        smooth_right = cv2.GaussianBlur(img_right, (3, 3), 0.5)
        
        # 2. ê¸°ë³¸ ì‹œì°¨ ê³„ì‚°
        disparity = self.stereo.compute(smooth_left, smooth_right)
        disparity = disparity.astype(np.float32) / 16.0
        
        # 3. ì„œë¸Œí”½ì…€ ì •ë°€ë„ í–¥ìƒ
        disparity_refined = self._subpixel_refinement(
            smooth_left, smooth_right, disparity
        )
        
        # 4. ì´ìƒì¹˜ ì œê±°
        disparity_filtered = self._remove_outliers(disparity_refined)
        
        return disparity_filtered
    
    def _subpixel_refinement(self, img_left, img_right, disparity):
        """ì„œë¸Œí”½ì…€ ì •ë°€ë„ í–¥ìƒ"""
        h, w = disparity.shape
        refined_disparity = disparity.copy()
        
        # ê° í”½ì…€ì— ëŒ€í•´ í¬ë¬¼ì„  í”¼íŒ…ìœ¼ë¡œ ì„œë¸Œí”½ì…€ ì •ë°€ë„ í–¥ìƒ
        for y in range(1, h-1):
            for x in range(1, w-1):
                d = int(disparity[y, x])
                if d <= 0 or d >= w-1:
                    continue
                
                # ì£¼ë³€ í”½ì…€ì—ì„œ ë§¤ì¹­ ë¹„ìš© ê³„ì‚°
                costs = []
                for dd in [d-1, d, d+1]:
                    if dd >= 0 and x-dd >= 0:
                        # SAD ê³„ì‚°
                        cost = abs(int(img_left[y, x]) - int(img_right[y, x-dd]))
                        costs.append(cost)
                    else:
                        costs.append(float('inf'))
                
                # í¬ë¬¼ì„  í”¼íŒ…ìœ¼ë¡œ ìµœì†Œê°’ ì°¾ê¸°
                if len(costs) == 3 and all(c != float('inf') for c in costs):
                    c0, c1, c2 = costs
                    if c0 != c2:  # ë¶„ëª¨ê°€ 0ì´ ì•„ë‹Œ ê²½ìš°
                        subpixel_offset = (c0 - c2) / (2 * (c0 - 2*c1 + c2))
                        refined_disparity[y, x] = d + subpixel_offset
        
        return refined_disparity
    
    def _measure_component_height(self, disparity, region, component_type):
        """ê°œë³„ ë¶€í’ˆ ë†’ì´ ì¸¡ì •"""
        x, y, w, h = region
        
        # ë¶€í’ˆ ì˜ì—­ì˜ ì‹œì°¨ ì¶”ì¶œ
        component_disparity = disparity[y:y+h, x:x+w]
        valid_disparities = component_disparity[component_disparity > 0]
        
        if len(valid_disparities) == 0:
            return {'height': None, 'confidence': 0}
        
        # í†µê³„ì  ë†’ì´ ê³„ì‚°
        depths = (self.focal_length * self.baseline) / valid_disparities
        
        # ë¶€í’ˆë³„ íŠ¹í™” ì¸¡ì •
        if component_type == 'resistor':
            # ì €í•­: ì¤‘ê°„ê°’ ì‚¬ìš© (ì´ìƒì¹˜ì— ê°•í•¨)
            height = np.median(depths)
        elif component_type == 'ic':
            # IC: 95 í¼ì„¼íƒ€ì¼ (ìµœê³ ì  ì¸¡ì •)
            height = np.percentile(depths, 95)
        else:
            # ê¸°ë³¸: í‰ê· ê°’
            height = np.mean(depths)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = len(valid_disparities) / (w * h)
        
        return {
            'height': height,
            'confidence': confidence,
            'std_dev': np.std(depths),
            'measurement_points': len(valid_disparities)
        }

# ì„±ëŠ¥ ë¶„ì„
def analyze_manufacturing_performance():
    """ì œì¡°ì—… ê²€ì‚¬ ì„±ëŠ¥ ë¶„ì„"""
    
    # ì¼ë°˜ì ì¸ ì„±ëŠ¥ ì§€í‘œ
    inspection_metrics = {
        'detection_precision': 0.973,   # 97.3% ì •ë°€ë„
        'detection_recall': 0.986,      # 98.6% ì¬í˜„ìœ¨
        'measurement_accuracy': 0.002,  # Â±2Î¼m ì¸¡ì • ì •í™•ë„
        'throughput': 120,              # PCBs per hour
    }
    
    f1_score = 2 * (inspection_metrics['detection_precision'] * inspection_metrics['detection_recall']) / \
               (inspection_metrics['detection_precision'] + inspection_metrics['detection_recall'])
    
    print("ğŸ­ ì œì¡°ì—… í’ˆì§ˆ ê²€ì‚¬ ì„±ëŠ¥ ì§€í‘œ:")
    print(f"ğŸ” ì •ë°€ë„ (Precision): {inspection_metrics['detection_precision']:.3f}")
    print(f"ğŸ“ ì¬í˜„ìœ¨ (Recall): {inspection_metrics['detection_recall']:.3f}")
    print(f"âš–ï¸ F1 Score: {f1_score:.3f}")
    print(f"ğŸ“ ì¸¡ì • ì •í™•ë„: Â±{inspection_metrics['measurement_accuracy']*1000:.0f}Î¼m")
    print(f"â±ï¸ ì²˜ë¦¬ ì†ë„: {inspection_metrics['throughput']} PCB/ì‹œê°„")
    
    return inspection_metrics
```

### ğŸ® ì„±ê³¼ ìš”ì•½ ë° êµí›ˆ

```python
def project_lessons_learned():
    """í”„ë¡œì íŠ¸ë³„ í•µì‹¬ êµí›ˆ"""
    
    lessons = {
        'ììœ¨ì£¼í–‰': [
            'ë™ì  í™˜ê²½ì—ì„œëŠ” ì‹œê°„ì  ì¼ê´€ì„±ì´ í•µì‹¬',
            'ROI ê¸°ë°˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ê³¼ ì •í™•ë„ ë™ì‹œ í™•ë³´',
            'ë‹¤ì¤‘ ì„¼ì„œ ìœµí•© (IMU, GPS)ìœ¼ë¡œ ì•ˆì •ì„± í–¥ìƒ',
            'ë‚ ì”¨, ì¡°ëª… ë³€í™”ì— ëŒ€í•œ robustí•œ ì „ì²˜ë¦¬ í•„ìˆ˜'
        ],
        
        'ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜': [
            'ì‹¤ë‚´ í™˜ê²½ì˜ í…ìŠ¤ì²˜ ë¶€ì¡± ë¬¸ì œ í•´ê²° ì¤‘ìš”',
            'ë°”ë‹¥/ì¥ì• ë¬¼ ë¶„ë¦¬ê°€ ì„±ê³µì˜ í•µì‹¬',
            'ì‹¤ì‹œê°„ ë§µ ì—…ë°ì´íŠ¸ë¡œ ë™ì  í™˜ê²½ ëŒ€ì‘',
            'ì €ì „ë ¥ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì ì‘ì  í’ˆì§ˆ ì¡°ì •'
        ],
        
        'ì œì¡°ì—… ê²€ì‚¬': [
            'ì •ë°€ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì´ ëª¨ë“  ê²ƒì„ ì¢Œìš°',
            'ì„œë¸Œí”½ì…€ ì²˜ë¦¬ë¡œ Î¼m ë‹¨ìœ„ ì •ë°€ë„ ë‹¬ì„±',
            'í†µê³„ì  ë°©ë²•ìœ¼ë¡œ ì¸¡ì • ì‹ ë¢°ë„ í–¥ìƒ',
            'ë¶€í’ˆë³„ íŠ¹í™”ëœ ì¸¡ì • ì „ëµ í•„ìš”'
        ]
    }
    
    print("ğŸ“š í”„ë¡œì íŠ¸ë³„ í•µì‹¬ êµí›ˆ:")
    for project, lesson_list in lessons.items():
        print(f"\nğŸ¯ {project}:")
        for lesson in lesson_list:
            print(f"  â€¢ {lesson}")
    
    return lessons

def performance_comparison():
    """í”„ë¡œì íŠ¸ë³„ ì„±ëŠ¥ ë¹„êµ"""
    
    comparison_data = {
        'ì¸¡ì • ë²”ìœ„': {
            'ììœ¨ì£¼í–‰': '5-50m',
            'ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜': '0.1-3m', 
            'ì œì¡°ì—… ê²€ì‚¬': '0.01-0.1m'
        },
        'ì •í™•ë„': {
            'ììœ¨ì£¼í–‰': 'Â±10cm',
            'ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜': 'Â±1cm',
            'ì œì¡°ì—… ê²€ì‚¬': 'Â±2Î¼m'
        },
        'ì²˜ë¦¬ ì†ë„': {
            'ììœ¨ì£¼í–‰': '35 FPS',
            'ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜': '15 FPS',
            'ì œì¡°ì—… ê²€ì‚¬': '2 FPS'
        },
        'ì‹œìŠ¤í…œ ë¹„ìš©': {
            'ììœ¨ì£¼í–‰': '$1,500',
            'ë¡œë´‡ ë‚´ë¹„ê²Œì´ì…˜': '$200',
            'ì œì¡°ì—… ê²€ì‚¬': '$5,000'
        }
    }
    
    import pandas as pd
    df = pd.DataFrame(comparison_data)
    print("ğŸ“Š í”„ë¡œì íŠ¸ë³„ ì„±ëŠ¥ ë¹„êµ:")
    print(df.to_string())
    
    return df
```

**ì‹œìŠ¤í…œ êµ¬í˜„ ì‹œ ê³ ë ¤ì‚¬í•­:**

ìŠ¤í…Œë ˆì˜¤ë¹„ì „ ì‹œìŠ¤í…œ ê°œë°œì—ì„œëŠ” ì™„ë²½í•œ ì†”ë£¨ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ê° ë„ë©”ì¸ë³„ë¡œ ìµœì í™”ëœ ì ‘ê·¼ì´ í•„ìš”í•˜ë©° í•­ìƒ trade-offë¥¼ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì€ **ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ê²€ì¦**ì…ë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ í˜„ì‹¤ì—ì„œëŠ” ì˜ˆìƒê³¼ ë‹¤ë¥´ê²Œ ë™ì‘í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¶©ë¶„í•œ ì‹¤í™˜ê²½ ë°ì´í„° ìˆ˜ì§‘ê³¼ ì§€ì†ì ì¸ ê°œì„ ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤.

---

## ğŸ¤ ì»¤ë®¤ë‹ˆí‹° & FAQ

### â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)

**Q1: ìŠ¤í…Œë ˆì˜¤ë¹„ì „ ì…ë¬¸ìì—ê²Œ ì¶”ì²œí•˜ëŠ” ì²« í”„ë¡œì íŠ¸ëŠ”?**

A: ì›¹ìº  2ëŒ€ë¡œ ê°„ë‹¨í•œ ê±°ë¦¬ ì¸¡ì •ê¸°ë¥¼ ë§Œë“¤ì–´ë³´ì„¸ìš”! ë³µì¡í•œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì—†ì´ë„ ìƒëŒ€ì  ê±°ë¦¬ëŠ” ì¶©ë¶„íˆ ì¸¡ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.

```python
# ì´ˆë³´ììš© ê°„ë‹¨ ê±°ë¦¬ ì¸¡ì •ê¸°
def simple_distance_meter():
    cap1 = cv2.VideoCapture(0)
    cap2 = cv2.VideoCapture(1)
    
    stereo = cv2.StereoBM_create(numDisparities=32, blockSize=15)
    
    while True:
        ret1, frame1 = cap1.read()
        ret2, frame2 = cap2.read()
        
        if ret1 and ret2:
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
            
            disparity = stereo.compute(gray1, gray2)
            
            # ì¤‘ì•™ í”½ì…€ì˜ ê±°ë¦¬ ì¶œë ¥
            center_disp = disparity[240, 320]
            if center_disp > 0:
                # ëŒ€ëµì  ê±°ë¦¬ (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”)
                approx_distance = 1000 / (center_disp / 16.0)
                cv2.putText(frame1, f"Distance: {approx_distance:.1f}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            cv2.imshow('Left', frame1)
            cv2.imshow('Disparity', disparity/16)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
```

**Q2: ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì´ ë„ˆë¬´ ì–´ë ¤ì›Œìš”. ê¼­ í•´ì•¼ í•˜ë‚˜ìš”?**

A: ì •í™•í•œ ì¸¡ì •ì´ í•„ìš”í•˜ë‹¤ë©´ í•„ìˆ˜ì…ë‹ˆë‹¤! í•˜ì§€ë§Œ ì²´ìŠ¤ë³´ë“œ ëŒ€ì‹  ArUco ë§ˆì»¤ë¥¼ ì‚¬ìš©í•˜ë©´ í›¨ì”¬ ì‰¬ì›Œì§‘ë‹ˆë‹¤.

**Q3: GPU ì—†ì–´ë„ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥í•œê°€ìš”?**

A: ê°€ëŠ¥í•©ë‹ˆë‹¤! í•´ìƒë„ ì¡°ì •, ROI ì²˜ë¦¬, ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ì¶©ë¶„íˆ ì‹¤ì‹œê°„ ë‹¬ì„± ê°€ëŠ¥í•´ìš”.

**Q4: ì•¼ì™¸ì—ì„œ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ì´ìœ ëŠ”?**

A: ì¡°ëª… ë³€í™”, ê·¸ë¦¼ì, ë°˜ì‚¬ ë•Œë¬¸ì…ë‹ˆë‹¤. HDR ì´¬ì˜ì´ë‚˜ í¸ê´‘ í•„í„°ê°€ ë„ì›€ë©ë‹ˆë‹¤.

**Q5: ì‹¤ì œ ì‚°ì—…ì—ì„œ ì–¼ë§ˆë‚˜ ì‚¬ìš©ë˜ë‚˜ìš”?**

A: ììœ¨ì£¼í–‰(Tesla, Waymo), ë¡œë´‡ê³µí•™(Boston Dynamics), ì œì¡°ì—…(ì‚¼ì„±, LG) ë“±ì—ì„œ ê´‘ë²”ìœ„í•˜ê²Œ í™œìš©ë©ë‹ˆë‹¤!

### ğŸ’¡ ê°œë°œì íŒ ëª¨ìŒ

```python
# íŒ 1: ë™ì  ROIë¡œ ì„±ëŠ¥ í–¥ìƒ
def dynamic_roi_processing(img_left, img_right, motion_vectors):
    """ì›€ì§ì„ ì •ë³´ë¥¼ í™œìš©í•œ ë™ì  ROI"""
    # ì›€ì§ì„ì´ ë§ì€ ì˜ì—­ë§Œ ê³ í’ˆì§ˆ ì²˜ë¦¬
    high_motion_regions = detect_motion_regions(motion_vectors)
    
    results = {}
    for region in high_motion_regions:
        roi_disparity = process_roi_high_quality(img_left, img_right, region)
        results[region] = roi_disparity
    
    return results

# íŒ 2: ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬
def batch_stereo_processing(image_pairs, batch_size=4):
    """ë°°ì¹˜ ë‹¨ìœ„ íš¨ìœ¨ì  ì²˜ë¦¬"""
    stereo = cv2.StereoBM_create(numDisparities=64, blockSize=15)
    
    for i in range(0, len(image_pairs), batch_size):
        batch = image_pairs[i:i+batch_size]
        
        # ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=batch_size) as executor:
            futures = [
                executor.submit(stereo.compute, left, right)
                for left, right in batch
            ]
            
            batch_results = [f.result() for f in futures]
            yield batch_results

# íŒ 3: ì‹¤íŒ¨ ê°ì§€ ë° ë³µêµ¬
def robust_stereo_with_fallback(img_left, img_right):
    """ì‹¤íŒ¨ ê°ì§€ ë° ëŒ€ì•ˆ ì²˜ë¦¬"""
    
    # 1ì°¨ ì‹œë„: ê³ í’ˆì§ˆ SGBM
    try:
        stereo_sgbm = cv2.StereoSGBM_create(...)
        disparity = stereo_sgbm.compute(img_left, img_right)
        
        # í’ˆì§ˆ ê²€ì‚¬
        valid_ratio = (disparity > 0).sum() / disparity.size
        if valid_ratio > 0.3:  # 30% ì´ìƒ ìœ íš¨
            return disparity, 'high_quality'
    except:
        pass
    
    # 2ì°¨ ì‹œë„: ë¹ ë¥¸ BM
    try:
        stereo_bm = cv2.StereoBM_create(numDisparities=32, blockSize=21)
        disparity = stereo_bm.compute(img_left, img_right)
        
        valid_ratio = (disparity > 0).sum() / disparity.size
        if valid_ratio > 0.2:  # 20% ì´ìƒ ìœ íš¨
            return disparity, 'medium_quality'
    except:
        pass
    
    # 3ì°¨ ì‹œë„: ì €í•´ìƒë„ ì²˜ë¦¬
    small_left = cv2.resize(img_left, None, fx=0.5, fy=0.5)
    small_right = cv2.resize(img_right, None, fx=0.5, fy=0.5)
    
    stereo_fast = cv2.StereoBM_create(numDisparities=16, blockSize=9)
    small_disparity = stereo_fast.compute(small_left, small_right)
    
    # ì—…ìŠ¤ì¼€ì¼
    disparity = cv2.resize(small_disparity, (img_left.shape[1], img_left.shape[0]))
    
    return disparity, 'low_quality'
```

### ğŸŒŸ êµ¬í˜„ ì‚¬ë¡€ ë¶„ì„

**ğŸš— ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ**: ì°¨ëŸ‰ìš© ìŠ¤í…Œë ˆì˜¤ë¹„ì „ ì ìš©
- **ê³¼ì œ**: ë„ì‹¬ ë³µì¡ í™˜ê²½ì—ì„œ ì‹¤ì‹œê°„ ê±°ë¦¬ ì¸¡ì •
- **í•´ê²°ì±…**: ë‹¤ì¤‘ í•´ìƒë„ ì²˜ë¦¬ + IMU ì„¼ì„œ ìœµí•©
- **ì„±ê³¼**: ë†’ì€ ì‹ ë¢°ì„±ì˜ ê±°ë¦¬ ì¸¡ì • ë‹¬ì„±

**ğŸ¤– ë¬¼ë¥˜ ìë™í™” ë¡œë´‡**: ì°½ê³  í™˜ê²½ 3D ì¸ì‹
- **ê³¼ì œ**: ë‹¤ì–‘í•œ í¬ê¸° ìƒìë“¤ì˜ ì •í™•í•œ 3D ì¸ì‹
- **í•´ê²°ì±…**: ì ì‘ì  ë² ì´ìŠ¤ë¼ì¸ + AI ë¬¼ì²´ ì¸ì‹ ìœµí•©
- **ì„±ê³¼**: íš¨ìœ¨ì ì¸ ë¬¼ë¥˜ ì²˜ë¦¬ ì‹œìŠ¤í…œ êµ¬í˜„

**ğŸ­ ì œì¡°ì—… í’ˆì§ˆ ê²€ì‚¬**: ê³ ì •ë°€ ì¸¡ì • ìë™í™”
- **ê³¼ì œ**: ë§ˆì´í¬ë¡œë¯¸í„° ë‹¨ìœ„ ë†’ì´ ì¸¡ì •
- **í•´ê²°ì±…**: ì´ˆê³ í•´ìƒë„ ì¹´ë©”ë¼ + í™˜ê²½ ì œì–´
- **ì„±ê³¼**: ì¸ê°„ ê²€ì‚¬ ëŒ€ë¹„ í–¥ìƒëœ ì†ë„ì™€ ì •í™•ë„

### ğŸ“– ì¶”ì²œ í•™ìŠµ ë¡œë“œë§µ

#### ğŸ¯ ì´ˆê¸‰ì (1-2ê°œì›”)
1. **1ì£¼ì°¨**: ì»´í“¨í„° ë¹„ì „ ê¸°ì´ˆ, OpenCV ì„¤ì¹˜
2. **2ì£¼ì°¨**: ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹¤ìŠµ
3. **3ì£¼ì°¨**: ê¸°ë³¸ ìŠ¤í…Œë ˆì˜¤ ë§¤ì¹­ (StereoBM)
4. **4ì£¼ì°¨**: ì‹œì°¨ë§µ ì‹œê°í™” ë° ë¶„ì„
5. **5-8ì£¼ì°¨**: ê°„ë‹¨í•œ ê±°ë¦¬ ì¸¡ì • í”„ë¡œì íŠ¸

#### ğŸš€ ì¤‘ê¸‰ì (3-4ê°œì›”)
1. **1ê°œì›”ì°¨**: SGBM, Census Transform ë“± ê³ ê¸‰ ì•Œê³ ë¦¬ì¦˜
2. **2ê°œì›”ì°¨**: í›„ì²˜ë¦¬ ê¸°ë²•, ì„±ëŠ¥ ìµœì í™”
3. **3ê°œì›”ì°¨**: ì‹¤ì‹œê°„ ì²˜ë¦¬, GPU ê°€ì†
4. **4ê°œì›”ì°¨**: ì‹¤ì œ ì‘ìš© í”„ë¡œì íŠ¸ (ë¡œë´‡/ììœ¨ì£¼í–‰)

#### ğŸ† ê³ ê¸‰ì (6ê°œì›”+)
1. **Deep Learning ê¸°ë°˜ ìŠ¤í…Œë ˆì˜¤**: PSMNet, GwcNet
2. **ë©€í‹°ë·° ìŠ¤í…Œë ˆì˜¤**: 3ê°œ ì´ìƒ ì¹´ë©”ë¼ í™œìš©
3. **SLAM ìœµí•©**: ë™ì‹œ ìœ„ì¹˜ ì¶”ì • ë° ì§€ë„ ì‘ì„±
4. **ì‚°ì—… íŠ¹í™”**: ë„ë©”ì¸ë³„ ìµœì í™” ê¸°ë²•

### ğŸ”— ìœ ìš©í•œ ë¦¬ì†ŒìŠ¤

#### ğŸ“š êµìœ¡ ìë£Œ
- [Stanford CS231A](http://web.stanford.edu/class/cs231a/) - ì»´í“¨í„° ë¹„ì „ ê°•ì˜
- [Multiple View Geometry](https://www.cambridge.org/core/books/multiple-view-geometry-in-computer-vision/0B6F289C78B2B23F596CAA76D3D43F7A) - ê¸°í•˜í•™ ì´ë¡ ì„œ
- [OpenCV-Python Tutorials](https://docs.opencv.org/master/d6/d00/tutorial_py_root.html)

#### ğŸ› ï¸ ê°œë°œ ë„êµ¬
- **Stereo Dataset**: [Middlebury](https://vision.middlebury.edu/stereo/), [KITTI](http://www.cvlibs.net/datasets/kitti/)
- **3D Visualization**: [Open3D](http://www.open3d.org/), [PCL](https://pointclouds.org/)
- **Deep Learning**: [PyTorch](https://pytorch.org/), [TensorFlow](https://tensorflow.org/)

#### ğŸ¢ ì—…ê³„ ë™í–¥
- **ë…¼ë¬¸**: [arXiv Computer Vision](https://arxiv.org/list/cs.CV/recent)
- **ì»¨í¼ëŸ°ìŠ¤**: CVPR, ICCV, ECCV, ICRA
- **ê¸°ì—… ë¸”ë¡œê·¸**: Waymo, Tesla, NVIDIA AI



**í•™ìŠµ ì •ë¦¬**

ìŠ¤í…Œë ˆì˜¤ë¹„ì „ì€ ë‹¨ìˆœíˆ ì¹´ë©”ë¼ ë‘ ëŒ€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒ ì´ìƒì˜ ë³µì¡í•œ ê¸°ìˆ ì…ë‹ˆë‹¤. ì„±ê³µì ì¸ êµ¬í˜„ì„ ìœ„í•´ì„œëŠ” ë‹¤ì–‘í•œ ê¸°ìˆ ì  ìš”ì†Œë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

ì™„ë²½í•œ ì†”ë£¨ì…˜ì€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, í•­ìƒ í™˜ê²½ê³¼ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì´ ê°€ì´ë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì¸ í•™ìŠµê³¼ ì‹¤ìŠµì„ í†µí•´ ìŠ¤í…Œë ˆì˜¤ë¹„ì „ ê¸°ìˆ ì„ ìŠµë“í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

---

