# 스테레오 비전 기술 과외 대본
## 컴퓨터 비전 전문 교육 프로그램

---

## 📋 수업 개요

### **과목명**: 스테레오 비전 기술의 이론과 실무
### **대상**: 컴퓨터 비전 입문자 및 중급자
### **총 수업 시간**: 3시간 (180분)
### **교육 방식**: 이론 강의 + 인터랙티브 실습 + 코딩 실습

### **학습 자료**
- **주교재**: 웹 기반 PPT (https://zk06-study.github.io/stereoVision_1.0/)
- **부교재**: 본 교육 대본 및 실습 코드
- **실습 환경**: Python, OpenCV, Jupyter Notebook

---

## 🎯 전체 교육 목표

본 과외를 통해 학습자는 다음과 같은 역량을 습득하게 됩니다:

1. **이론적 이해**: 스테레오 비전의 수학적 원리와 핵심 개념 이해
2. **알고리즘 분석**: 주요 스테레오 매칭 알고리즘의 특성과 적용 방법 습득
3. **실무 구현**: OpenCV를 활용한 실제 스테레오 비전 시스템 구현
4. **문제 해결**: 실무에서 발생하는 문제 진단 및 해결 능력 배양

---

# 1교시: 스테레오 비전 기초 이론 (60분)

## 📖 수업 시작 (5분)

**강사**: "안녕하세요. 오늘부터 우리는 스테레오 비전이라는 아주 흥미로운 기술에 대해 체계적으로 학습해보겠습니다. 수업을 위해 먼저 웹 브라우저를 열고 다음 주소로 접속해주세요."

**PPT 주소**: https://zk06-study.github.io/stereoVision_1.0/

**강사**: "지금부터 이 슬라이드를 보면서 수업을 진행하겠습니다. 슬라이드는 키보드 방향키로 넘길 수 있습니다. 수업 중간에 궁금한 점이 생기면 언제든지 편하게 질문해주세요."

---

## 📚 슬라이드 1-2: 스테레오 비전 개념 소개 (15분)

### **슬라이드 1: 타이틀**

**강사**: "첫 번째 슬라이드는 오늘 우리가 배울 주제인 '스테레오 비전 학습 가이드'입니다. 부제처럼, 컴퓨터가 두 개의 눈으로 세상을 입체적으로 이해하는 기술의 모든 것을 다뤄볼 예정입니다."

### **슬라이드 2: 스테레오 비전 개요**

**강사**: "자, 그럼 다음 슬라이드로 넘어가서 스테레오 비전이 무엇인지 본격적으로 알아보겠습니다."

**강사**: "슬라이드 왼쪽을 보시면, 스테레오 비전은 **두 개의 카메라**를 사용해서 3차원 깊이 정보를 얻는 기술이라고 정의되어 있습니다. 이것은 우리 인간이 두 눈의 미세한 각도 차이를 이용해 사물과의 거리를 자연스럽게 인지하는 **양안시(Binocular Vision)** 원리를 그대로 모방한 것입니다."

**강사**: "가장 큰 장점은 LiDAR나 레이더 같은 고가의 3D 센서에 비해 **저비용**이라는 점입니다. 일반 카메라 두 대만 있으면 되니까요. 이 덕분에 정말 다양한 분야에서 활발하게 사용되고 있습니다. 오른쪽 카드를 함께 보실까요?"

### **응용 분야 상세 설명**

**강사**: "첫 번째로 **자율주행** 분야입니다. 아마 가장 많이 들어보셨을 겁니다. 차량 전방에 달린 두 카메라가 앞차와의 거리, 보행자의 위치, 차선 등을 실시간으로 측정하여 충돌을 방지하고 안전한 주행을 돕습니다. 테슬라가 비전 기술을 중심으로 자율주행을 구현하는 대표적인 예시죠."

**강사**: "두 번째는 **로보틱스**, 특히 SLAM(동시적 위치 추정 및 지도 작성) 기술입니다. 로봇이 집이나 공장 같은 낯선 환경을 돌아다니면서 지도를 그리고, 동시에 장애물을 피하려면 주변 환경의 3차원 구조를 알아야 합니다. 바로 이 역할을 스테레오 카메라가 수행합니다. 요즘 많이 쓰는 로봇 청소기나 서빙 로봇에 이 기술이 들어가 있습니다."

**강사**: "세 번째는 **AR/VR**입니다. 증강현실(AR) 안경이 현실 공간에 가상 객체를 자연스럽게 띄우려면, 책상이나 바닥이 어디 있는지 정확히 알아야 합니다. 스테레오 카메라는 이처럼 현실 공간의 깊이를 측정해서 가상과 현실을 정교하게 융합시키는 역할을 합니다."

**강사**: "네 번째, **3D 모델링**입니다. 건물이나 유적, 심지어 사람의 얼굴을 3D로 스캔할 때도 스테레오 비전이 사용됩니다. 여러 각도에서 촬영한 스테레오 이미지로부터 깊이 정보를 추출하고 합쳐서 사실적인 3차원 모델을 만들어내는 것이죠."

**강사**: "이 외에도 수술 부위의 깊이를 측정하는 **의료 영상**이나, 공장에서 생산된 부품의 미세한 높이 차이를 검사하는 **품질 검사** 등 정말 무궁무진하게 활용되고 있습니다. 이 중에서 어떤 분야가 가장 흥미로우신가요? 나중에 해당 분야의 케이스 스터디를 더 자세히 다뤄보겠습니다."

---

## 📚 슬라이드 3: 목차 (3분)

**강사**: "다음 슬라이드는 오늘 우리가 학습할 내용의 전체적인 목차입니다. 크게 7가지 주제로 구성되어 있습니다."

1.  **StereoVision이란?**: 기본 개념과 장단점을 다시 한번 짚어봅니다.
2.  **3차원 거리 계산 원리**: 어떤 수학적 원리로 거리를 계산하는지 알아봅니다.
3.  **스테레오 매칭과 시차 맵**: 기술의 핵심인 매칭 과정과 그 결과물을 이해합니다.
4.  **Python 코드 구현**: 이론을 바탕으로 실제 코드를 작성해봅니다.
5.  **실무 트러블슈팅**: 현장에서 발생하는 문제와 해결책을 다룹니다.
6.  **성능 최적화**: 더 빠르고 효율적인 시스템을 만드는 노하우를 배웁니다.
7.  **프로젝트 케이스 스터디**: 실제 산업 적용 사례를 분석합니다.

**강사**: "이 순서대로 차근차근 진행될 예정이니, 전체적인 흐름을 머리에 그려두시면 이해에 도움이 될 겁니다."

---

## 📚 슬라이드 4: StereoVision이란? (7분)

**강사**: "네 번째 슬라이드에서는 스테레오 비전의 개념을 다시 한번 정리해보겠습니다. 왼쪽의 기본 개념을 봐주세요."

**강사**: "핵심 키워드는 **시차(Disparity)** 입니다. 왼쪽 카메라 영상과 오른쪽 카메라 영상에서 같은 물체가 약간 다른 위치에 보이는데, 이 픽셀 위치의 차이를 '시차'라고 부릅니다. 이 시차 값이 바로 깊이, 즉 거리를 계산하는 열쇠가 됩니다."

**강사**: "오른쪽 그림을 보시면 두 카메라가 약간 다른 각도에서 같은 피사체를 보고 있는 것을 확인할 수 있습니다. 이 차이가 시차를 만들어내는 원리입니다."

**강사**: "아래쪽의 장단점을 보겠습니다. **장점**은 앞서 말했듯 저비용이고, 시스템 구성이 간단하다는 점입니다. 반면 **단점**은 LiDAR에 비해 정확도가 상대적으로 낮고, 조명 변화에 민감하다는 것입니다. 또한, 무늬가 없는 흰 벽처럼 **텍스처가 없는 표면**에서는 대응점을 찾기 어려워 깊이 측정이 실패하는 한계가 있습니다. 이런 특징들을 잘 이해해야 상황에 맞는 기술을 선택할 수 있습니다."

---

## 🔬 슬라이드 5: 3차원 거리 계산 원리 (15분)

**강사**: "자, 이제 스테레오 비전의 가장 핵심적인 수학 원리를 배워보겠습니다. 슬라이드 5번을 봐주세요. 조금 복잡해 보일 수 있지만, 중학교 때 배운 '삼각형의 닮음' 원리만 이해하면 아주 간단합니다."

**강사**: "왼쪽 그림은 스테레오 카메라의 기하학적 구조를 위에서 본 모습입니다. 두 카메라 렌즈의 중심(광심)과 실제 공간의 한 점(P)이 만드는 두 개의 직각삼각형이 보일 겁니다. 이 두 삼각형은 서로 닮음 관계에 있습니다."

**강사**: "이 닮음 관계를 이용해 비례식을 세우고 정리하면, 오른쪽과 같은 간단한 공식이 나옵니다."

### **Z = (f × b) / d**

**강사**: "이 공식만 외우면 스테레오 비전의 절반은 이해한 겁니다. 각 변수가 무엇을 의미하는지 하나씩 살펴보겠습니다."

*   **Z (Depth)**: 우리가 최종적으로 알고 싶은 '깊이', 즉 카메라로부터 물체까지의 실제 거리입니다. 보통 미터(m) 단위로 구합니다.
*   **f (Focal Length)**: 카메라 렌즈의 '초점 거리'입니다. 렌즈와 이미지 센서 사이의 거리인데, 여기서는 픽셀(pixel) 단위로 환산된 값을 사용합니다. 이 값은 카메라 캘리브레이션을 통해 얻을 수 있습니다.
*   **b (Baseline)**: 두 카메라 사이의 '기준선' 거리입니다. 이것 역시 미터(m) 단위로, 우리가 직접 자로 잴 수 있는 값입니다.
*   **d (Disparity)**: '시차'입니다. 왼쪽 이미지에서의 x좌표와 오른쪽 이미지에서의 x좌표의 차이값(x_L - x_R)이며, 단위는 픽셀입니다.

**강사**: "공식을 다시 한번 보세요. Z와 d는 서로 반비례 관계에 있습니다. 즉, **시차(d)가 클수록 거리가 가깝고, 시차(d)가 작을수록 거리가 멀다**는 의미입니다. 이건 매우 중요하니 꼭 기억해주세요. 우리가 가까운 물체를 볼 때 두 눈이 안쪽으로 더 많이 모이는 것과 같은 원리입니다."

**강-사**: "이해를 돕기 위해 간단한 계산 예제를 풀어볼까요? 만약 카메라의 초점거리(f)가 800픽셀이고, 베이스라인(b)이 0.12미터(12cm)일 때, 어떤 물체의 시차(d)가 40픽셀로 측정되었다면 거리는 얼마일까요?"

**계산**: Z = (800 × 0.12) / 40 = 96 / 40 = 2.4 미터.

**강사**: "이렇게 시차 값만 알면 실제 거리를 바로 계산할 수 있습니다. 하지만 여기서 f와 b 값은 미리 정확하게 알고 있어야겠죠? 이 정확한 값을 얻는 과정을 **카메라 캘리브레이션**이라고 하며, 정확한 거리 측정의 가장 중요한 첫걸음입니다."

---

## 🎯 슬라이드 6: 스테레오 매칭과 시차 맵 (10분)

**강사**: "거리 계산 공식에서 시차(d)가 핵심이라고 말씀드렸죠? 그럼 이 시차는 어떻게 구할까요? 그 과정이 바로 '스테레오 매칭'입니다. 6번 슬라이드를 함께 보겠습니다."

**강사**: "스테레오 매칭이란, 슬라이드 설명처럼 **왼쪽 영상의 한 픽셀(또는 작은 영역)과 정확히 동일한 지점을 오른쪽 영상에서 찾아내는 과정**입니다. 컴퓨터가 두 영상 사이에서 '틀린 그림 찾기'를 하는 것과 비슷합니다."

**강사**: "슬라이드 가운데 그림을 보세요. **입력**으로 카메라 캘리브레이션과 영상 보정이 끝난 좌/우 이미지 한 쌍이 들어갑니다. 그러면 스테레오 매칭 알고리즘이 이 두 이미지를 비교해서 각 픽셀의 시차 값을 계산하고, 그 결과를 **시차 맵(Disparity Map)** 이라는 흑백 이미지로 출력합니다."

**강사**: "오른쪽에 있는 시차 맵을 해석하는 방법을 알려드리겠습니다. 매우 직관적입니다."
*   **밝은 회색/흰색**: 시차 값이 크다는 의미. 즉, 카메라에 **가까운** 물체입니다.
*   **어두운 회색/검은색**: 시차 값이 작다는 의미. 즉, 카메라에서 **먼** 물체입니다.

**강사**: "실습 질문입니다. 슬라이드의 시차 맵 예시에서 가장 밝게 보이는 부분이 자동차 앞부분인데, 이것은 무엇을 의미할까요? 네, 맞습니다. 자동차가 배경보다 우리에게 훨씬 가깝다는 뜻입니다. 이처럼 시차 맵은 2D 이미지에 3D 깊이 정보를 시각적으로 표현한 결과물이라고 할 수 있습니다."

---

# 2교시: 알고리즘 이해 및 실습 (60분)

## 🔍 슬라이드 7: 알고리즘 분류 및 특성 (15분)

**강사**: "2교시를 시작하겠습니다. 이제 스테레오 매칭을 수행하는 알고리즘에는 어떤 종류가 있는지 알아보겠습니다. 슬라이드 7번을 봐주세요. 알고리즘은 크게 **지역 정합(Local)** 과 **전역 정합(Global)**, 두 가지 방식으로 나뉩니다."

### **지역 정합 (Local Matching)**

**강사**: "먼저 왼쪽의 지역 정합입니다. 이름 그대로, 이미지의 **특정 윈도우(작은 사각형 영역)만 보고** 비용을 계산합니다. 예를 들어 왼쪽 이미지의 3x3 픽셀 영역과 가장 비슷한 영역을 오른쪽 이미지에서 찾는 식입니다. 주변 픽셀들은 전혀 고려하지 않습니다."
*   **특징**: "속도가 매우 빠르고, 구현이 간단하며, 하드웨어로 만들기도 좋습니다. 그래서 실시간성이 중요한 자율주행이나 로보틱스 분야에서 널리 쓰입니다."
*   **단점**: "하지만 시야가 좁기 때문에 정확도는 보통 수준입니다. 특히 무늬가 없는 벽이나 반복되는 패턴(예: 바둑판 무늬)에서는 잘못된 짝을 찾을 확률이 높습니다. 대표적인 알고리즘으로는 오늘 우리가 체험해 볼 SAD, SSD, Census 등이 있습니다."

### **전역 정합 (Global Matching)**

**강사**: "다음은 오른쪽의 전역 정합입니다. 이 방식은 지역 정합과 반대로, **이미지 전체 픽셀 간의 관계를 모두 고려**해서 시차를 결정합니다. 하나의 픽셀 시차를 결정하기 위해 다른 모든 픽셀의 시차 후보까지 참고하는, 매우 신중한 방식입니다."
*   **특징**: "전체적인 맥락을 보기 때문에 정확도가 매우 높고, 객체의 경계선을 아주 깔끔하게 표현해냅니다."
*   **단점**: "하지만 모든 관계를 따지다 보니 계산량이 어마어마하게 많고 속도가 매우 느립니다. 그래서 실시간 처리보다는, 최고의 정밀도가 요구되는 의료 영상 분석이나 3D 모델링, 산업용 정밀 검사 같은 오프라인 작업에 주로 사용됩니다. Graph Cuts, Belief Propagation, SGM 같은 알고리즘이 여기에 속합니다."

**강사**: "실무에서는 이처럼 속도와 정확도라는 두 마리 토끼 사이에서 줄다리기를 해야 합니다. 어떤 가치를 더 중요하게 생각하느냐에 따라 적절한 알고리즘을 선택하는 것이 엔지니어의 역량이라고 할 수 있습니다."

---

## 💻 슬라이드 8-9: 인터랙티브 알고리즘 실습 (25분)

**강사**: "자, 이제 이론은 잠시 접어두고, 가장 기본적인 지역 정합 알고리즘들이 어떻게 동작하는지 직접 체험해보겠습니다. 8번 슬라이드로 이동해주세요. 3개의 카드가 보일 겁니다. 먼저 각 카드를 클릭해서 상세 설명을 열어보세요."

### **슬라이드 8: 알고리즘 상세 카드**

**강사**: "각 카드를 클릭하면 공식과 간단한 설명, 장단점이 나옵니다. 먼저 **SAD(Sum of Absolute Differences)** 카드를 클릭해볼까요? 픽셀값 차이의 '절댓값' 합이라고 되어있죠. 매우 직관적이고 빠릅니다. 다음은 **SSD(Sum of Squared Differences)** 입니다. 이번엔 차이의 '제곱' 합입니다. 제곱을 하기 때문에 큰 오차에 더 큰 페널티를 주게 되어 SAD보다 좀 더 정확한 경향이 있습니다. 마지막으로 **Census Transform**은 좀 독특합니다. 픽셀값 자체가 아니라, 중심 픽셀보다 주변 픽셀이 큰지 작은지를 따져서 0과 1로 구성된 비트 패턴을 만듭니다. 값의 상대적인 관계를 보기 때문에 조명 변화에 매우 강한 특징이 있습니다."

### **슬라이드 9: 인터랙티브 계산기 실습**

**강사**: "이제 9번 슬라이드로 넘어가서, 이 알고리즘들을 직접 계산해보겠습니다. 3개의 계산기가 있습니다."

#### **SAD 실습**
**강사**: "첫 번째 SAD 계산기를 봅시다. 좌측 윈도우와 우측 윈도우에 3x3 픽셀 값들이 미리 입력되어 있습니다. 'SAD 비용 계산' 버튼을 눌러보세요."
**강사**: "버튼을 누르면 아래 '계산 과정' 창에 각 픽셀 쌍의 차이와 누적 합계가 순서대로 표시됩니다. 예를 들어 첫 번째 픽셀은 |85 - 88| = 3, 두 번째는 |90 - 92| = 2, 이런 식으로 9개의 차이를 모두 더해서 최종 비용이 계산되는 것을 확인할 수 있습니다. 직접 손으로도 한번 계산해보세요. 이 비용 값이 가장 작게 나오는 후보 윈도우가 최종 매칭 영역이 되는 겁니다."

#### **SSD 실습**
**강사**: "다음은 SSD 계산기입니다. 같은 값으로 'SSD 비용 계산' 버튼을 눌러보겠습니다. 이번에는 과정이 조금 다르죠? (85 - 88)² = (-3)² = 9, (90 - 92)² = (-2)² = 4. 이런 식으로 제곱한 값들을 더해나갑니다. SAD 결과와 비교했을 때 최종 비용 값이 훨씬 커진 것을 볼 수 있습니다. 큰 오차가 더 부각되기 때문이죠."

#### **Census Transform 실습**
**강사**: "마지막으로 Census 계산기입니다. 여기는 윈도우가 하나만 있죠. 중심 픽셀인 100을 기준으로 주변 8개 픽셀의 값을 비교합니다. 'Census 비트 패턴 생성' 버튼을 눌러보세요."
**강사**: "계산 과정을 보면, 120은 100보다 크거나 같으니 1, 125도 1, ... , 90은 100보다 작으니 0, 이런 식으로 8개의 비트(0 또는 1)를 생성해서 '11110100'이라는 이진 패턴을 만드는 것을 볼 수 있습니다. 컴퓨터는 이 비트 패턴을 가지고 좌우 영상의 윈도우가 얼마나 비슷한지 비교합니다. 이 비교는 보통 해밍 거리(Hamming Distance)라는 기법을 사용합니다."

**강사**: "이렇게 직접 체험해보니 각 알고리즘의 차이점이 좀 더 명확하게 와 닿으시나요? 이 세 가지가 지역 정합의 가장 기본이 되는 아이디어입니다."

---

# 3교시: 실무 구현 및 응용 (60분)

## 💻 슬라이드 10: OpenCV 실무 구현 (20분)

**강사**: "3교시를 시작하겠습니다. 이제 이론과 실습을 바탕으로 실제 파이썬 코드를 작성해보겠습니다. 슬라이드 10번을 봐주세요. 우리는 세계에서 가장 널리 쓰이는 컴퓨터 비전 라이브러리인 OpenCV를 사용할 겁니다."

**강사**: "OpenCV는 매우 강력하고 최적화가 잘 된 스테레오 매칭 알고리즘을 제공합니다. 그중에서도 실무에서 가장 널리 쓰이는 **StereoSGBM** 알고리즘을 사용해보겠습니다. SGBM은 Semi-Global Block Matching의 약자로, 지역 정합의 빠른 속도와 전역 정합의 높은 정확도라는 장점을 절충한 아주 훌륭한 알고리즘입니다."

**강사**: "슬라이드에 있는 코드를 함께 보겠습니다."

```python
import cv2
import numpy as np

def advanced_stereo_matching(imgL, imgR):
    window_size = 5
    stereo = cv2.StereoSGBM_create(
        minDisparity=0,
        numDisparities=64,
        blockSize=window_size,
        P1=8 * 3 * window_size ** 2,
        P2=32 * 3 * window_size ** 2,
        disp12MaxDiff=1,
        uniquenessRatio=10,
        speckleWindowSize=100,
        speckleRange=32
    )
    disparity = stereo.compute(imgL, imgR).astype(np.float32) / 16.0
    return disparity
```

**강사**: "`cv2.StereoSGBM_create()` 함수를 호출하면서 여러 파라미터를 설정하는 것을 볼 수 있습니다. 이 파라미터들을 어떻게 조정하느냐에 따라 시차 맵의 품질이 천차만별로 달라지기 때문에, 각 파라미터의 의미를 이해하는 것이 실무에서 매우 중요합니다."

*   `minDisparity`: 최소 시차 값입니다. 보통 0으로 둡니다.
*   `numDisparities`: 시차 탐색 범위입니다. 이미지에서 찾을 최대 시차 값으로, 클수록 먼 거리까지 탐색하지만 계산량이 늘어납니다. 항상 16의 배수여야 합니다.
*   `blockSize`: 매칭에 사용할 윈도우(블록)의 크기입니다. 홀수 값만 가능하며, 보통 3~11 사이의 값을 사용합니다.
*   `P1`, `P2`: 시차의 부드러움을 제어하는 페널티 값입니다. 이웃한 픽셀 간 시차가 크게 변할 때 페널티를 부과해서 결과물을 부드럽게 만들어줍니다. 항상 `P2 > P1`이어야 합니다.
*   `uniquenessRatio`: 매칭의 신뢰도를 결정합니다. 찾은 최적의 매칭 비용이 두 번째로 좋은 비용보다 얼마나 더 좋은지를 나타내는 비율입니다. 높을수록 신뢰도 높은 매칭만 남깁니다.
*   `speckleWindowSize`, `speckleRange`: 노이즈 제거 필터 관련 파라미터입니다. 시차 맵에서 작은 점처럼 튀는 노이즈들을 제거해줍니다.

**강사**: "이 파라미터들은 정답이 없습니다. 내가 사용하는 카메라의 사양, 촬영 환경, 분석 대상에 따라 최적의 값이 모두 다릅니다. 그래서 실무 엔지니어는 수많은 테스트를 통해 이 값들을 '튜닝'하는 데 많은 시간을 보냅니다."

**강사**: "함수의 마지막 부분을 보면 `.compute()` 메소드로 실제 시차 계산을 수행하고, 그 결과를 16으로 나눠주는 것을 볼 수 있습니다. OpenCV 내부 계산 방식 때문에 16배 된 값이 나오므로, 실제 시차 값을 얻기 위해 나눠주는 과정이 필요합니다. 이제 이 함수를 이용해 실제 이미지로 시차 맵을 만들어보는 실습을 진행하겠습니다."

---

## 🔧 슬라이드 11: 실무 트러블슈팅 가이드 (15분)

**강사**: "코드를 돌려보면 알겠지만, 처음부터 완벽한 시차 맵이 나오는 경우는 거의 없습니다. 슬라이드 11번을 보면서 실무에서 자주 마주치는 문제들과 해결 방법을 알아보겠습니다."

### **문제 1: 시차 맵에 노이즈가 너무 많을 때**
**강사**: "왼쪽 카드 내용입니다. 시차 맵이 전체적으로 지글지글하거나, 점들이 눈처럼 흩날리는 경우가 아주 흔합니다."
*   **원인 1. 카메라 캘리브레이션 오류**: "가장 먼저 의심해야 할 부분입니다. 캘리브레이션이 조금이라도 틀어지면, 좌우 영상의 대응점이 정확히 같은 수평선 상에 놓이지 않게 되어 매칭 에러가 기하급수적으로 늘어납니다. 재투영 오차(Reprojection Error)를 계산해서 0.5픽셀 이하인지 반드시 확인해야 합니다."
*   **원인 2. 텍스처 부족**: "조명이 어둡거나, 흰 벽처럼 무늬 없는 영역을 촬영하면 컴퓨터가 대응점을 찾을 특징이 없어서 매칭에 실패합니다. 이럴 땐 조명을 추가하거나, 인위적으로 패턴을 쏴주는 프로젝터를 사용하기도 합니다."
*   **해결책**: "코드에서는 SGBM의 `uniquenessRatio` 값을 높여서 신뢰도 낮은 점들을 제거하거나, `speckle` 관련 파라미터를 조정해서 노이즈를 필터링할 수 있습니다. 또한, 시차 맵 결과에 Median Filter 같은 후처리 필터를 적용하는 것도 좋은 방법입니다."

### **문제 2: 특정 영역 매칭이 안될 때**
**강사**: "오른쪽 카드입니다. 반복되는 패턴(커튼, 줄무늬 옷), 햇빛이 강하게 반사되어 하얗게 날아간 영역(과노출), 또는 한쪽 카메라에만 보이는 가려진 영역(Occlusion) 등은 매칭이 매우 어렵습니다."
*   **해결책 1. 전처리**: "CLAHE(Contrast Limited Adaptive Histogram Equalization) 같은 기법으로 이미지의 대비를 높여서 숨어있는 텍스처를 살려낼 수 있습니다."
*   **해결책 2. 알고리즘 융합**: "예를 들어 조명에 강한 Census와 경계선 표현이 좋은 SAD의 비용을 가중 합산해서 사용하는 식으로 단점을 보완할 수 있습니다."
*   **해결책 3. 신뢰도 체크**: "OpenCV에서는 좌->우 매칭 결과와 우->좌 매칭 결과를 비교하는 **Left-Right Consistency Check**를 통해 신뢰도가 낮은 영역(주로 가려진 영역)을 검출하고 제거하는 기능을 제공합니다. `disp12MaxDiff` 파라미터가 바로 그 역할을 합니다."

**강사**: "이런 문제 해결 과정이 바로 스테레오 비전 엔지니어의 핵심 역량이라고 할 수 있습니다."

---

## 🚀 슬라이드 12: 성능 최적화 노하우 (10분)

**강사**: "실시간 시스템을 만들려면 정확도만큼이나 처리 속도도 중요합니다. 슬라이드 12번에서는 시차 맵 계산 속도를 높이는 4가지 대표적인 방법을 소개합니다."

1.  **해상도 낮추기**: "가장 간단하고 가장 효과적인 방법입니다. 이미지의 가로, 세로를 절반으로 줄이면 처리해야 할 픽셀 수가 1/4로 줄어들어 계산량이 극적으로 감소합니다. `cv2.resize()` 함수를 사용하면 됩니다."
2.  **관심 영역(ROI) 처리**: "화면 전체가 아니라, 우리가 정말로 깊이 정보를 원하는 영역(예: 자율주행에서의 도로 영역)만 잘라서 처리하는 방식입니다. 불필요한 계산을 줄여 속도를 높일 수 있습니다."
3.  **프레임 스키핑**: "초당 30프레임 영상이 들어온다고 해서 매 프레임마다 시차 맵을 계산할 필요는 없을 수 있습니다. 2~3 프레임에 한 번씩만 계산하고, 그 사이 프레임은 이전 결과를 그대로 사용하는 방식으로 전체적인 시스템 부하를 줄일 수 있습니다."
4.  **GPU 가속 (CUDA)**: "궁극의 최적화 방법입니다. OpenCV는 NVIDIA GPU의 병렬 처리 기능인 CUDA를 지원합니다. `cv2.cuda.StereoBM` 같은 CUDA용 함수를 사용하면 CPU로 처리할 때보다 수십 배 이상 빠른 속도를 얻을 수 있습니다. 다만, GPU가 장착된 시스템에서만 사용할 수 있습니다."

**강사**: "실무에서는 이 기법들을 복합적으로 사용해서 요구되는 성능 목표(예: 30fps)를 만족시키게 됩니다."

---

## 🚀 슬라이드 13-14: 케이스 스터디 및 Q&A (10분)

### **슬라이드 13: 실제 프로젝트 케이스 스터디**

**강사**: "이제 실제 산업 현장에서 스테레오 비전이 어떻게 사용되는지 세 가지 사례를 통해 보겠습니다. 각 사례마다 요구사항이 다르고, 그에 따라 SGBM 파라미터 설정이나 최적화 전략이 어떻게 달라지는지 눈여겨보세요."
*   **자율주행**: "가장 중요한 것은 **실시간성**과 **넓은 측정 범위**입니다. 따라서 `numDisparities`를 크게 하고, `blockSize`도 적당히 키우며, `uniquenessRatio`는 약간 낮춰서 속도를 확보하는 전략을 사용합니다. ROI 처리로 도로 영역에 집중하는 것도 필수적입니다."
*   **실내 로봇**: "가정용 로봇은 **저전력, 저비용**이 중요하고 측정 거리가 짧습니다. 따라서 저렴한 저해상도 카메라를 쓰고, SGBM 대신 더 가벼운 StereoBM 알고리즘을 사용하기도 합니다. 바닥과 장애물을 구분하는 것이 주된 목표입니다."
*   **제조업 검사**: "속도보다는 **최고의 정밀도**가 생명입니다. 고해상도 카메라를 사용하고, `blockSize`는 아주 작게, `numDisparities`는 매우 크게, `uniquenessRatio`는 아주 높게 설정해서 단 하나의 오차도 용납하지 않겠다는 전략을 씁니다. 후처리 필터링도 매우 정교하게 적용됩니다."

### **슬라이드 14: Q&A**

**강사**: "자주 묻는 질문 두 가지를 통해 개념을 한번 더 정리해보겠습니다."
*   **Q1. 캘리브레이션, 꼭 해야 하나요?**: "답은 '정확한 미터 단위 거리를 원한다면 무조건'입니다. 캘리브레이션은 픽셀 세계의 좌표를 현실 세계의 미터 좌표로 바꿔주는 '번역기'입니다. 이게 틀어지면 모든 계산이 의미가 없어집니다."
*   **Q2. 딥러닝이 항상 좋은가요?**: "그렇지 않습니다. 딥러닝 기반 모델은 학습한 데이터와 유사한 환경에서는 최고의 성능을 내지만, 처음 보는 낯선 환경에서는 성능이 급격히 저하될 수 있는 **일반화 성능** 이슈가 있습니다. 또한, 매우 무겁고 비싼 GPU 자원을 필요로 하므로, 가볍고 안정적인 성능이 중요한 임베디드 환경에서는 여전히 SGBM 같은 전통적인 방식이 훨씬 효율적일 수 있습니다."

---

## 🎓 슬라이드 15: 수업 정리 (5분)

**강사**: "오늘 배운 내용을 마지막으로 정리해보겠습니다."

1.  **이론**: 스테레오 비전은 두 카메라의 **시차(Disparity)**를 이용해 거리를 측정하며, 핵심 공식은 **Z = (f × b) / d** 이다.
2.  **알고리즘**: 속도가 빠른 **지역 정합**(SAD, SSD, Census)과 정확도가 높은 **전역 정합**이 있으며, 실무에서는 두 장점을 절충한 SGBM이 널리 쓰인다.
3.  **구현**: **OpenCV**의 `StereoSGBM`을 사용하며, 다양한 **파라미터 튜닝**을 통해 성능을 최적화하는 것이 핵심이다.
4.  **응용**: **자율주행, 로보틱스, 제조업** 등 각 분야의 요구사항에 맞춰 알고리즘과 파라미터를 다르게 적용해야 한다.

### **과제 및 다음 단계**

**강사**: "오늘 배운 내용을 완전히 자기 것으로 만들기 위한 과제를 드리겠습니다. 제공된 샘플 이미지와 코드를 가지고, SGBM 파라미터를 여러 가지로 바꿔보면서 시차 맵 결과가 어떻게 달라지는지 직접 관찰하고 리포트를 작성해보세요. 파라미터 값의 변화와 그에 따른 결과 변화의 이유를 분석해보는 것이 중요합니다."

**강사**: "오늘 수업은 여기서 마치겠습니다. 긴 시간 동안 고생 많으셨습니다. 궁금한 점이 있다면 언제든지 편하게 연락주세요. 감사합니다!"

---

## 📚 참고 자료

- **웹 PPT**: https://zk06-study.github.io/stereoVision_1.0/
- **GitHub 저장소**: https://github.com/ZK06-study/stereoVision_1.0
- **OpenCV 공식 문서**: https://docs.opencv.org/
- **실습 코드**: `python_examples/` 디렉토리 참조 